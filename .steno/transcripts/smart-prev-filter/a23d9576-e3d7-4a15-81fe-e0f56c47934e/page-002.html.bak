<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Claude Code transcript - page 2</title>
    <style>
:root { --bg-color: #f5f5f5; --card-bg: #ffffff; --user-bg: #e3f2fd; --user-border: #1976d2; --assistant-bg: #f5f5f5; --assistant-border: #9e9e9e; --thinking-bg: #fff8e1; --thinking-border: #ffc107; --thinking-text: #666; --tool-bg: #f3e5f5; --tool-border: #9c27b0; --tool-result-bg: #e8f5e9; --tool-error-bg: #ffebee; --text-color: #212121; --text-muted: #757575; --code-bg: #263238; --code-text: #aed581; }
* { box-sizing: border-box; }
body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: var(--bg-color); color: var(--text-color); margin: 0; padding: 16px; line-height: 1.6; }
.container { max-width: 800px; margin: 0 auto; }
h1 { font-size: 1.5rem; margin-bottom: 24px; padding-bottom: 8px; border-bottom: 2px solid var(--user-border); }
.header-row { display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 12px; border-bottom: 2px solid var(--user-border); padding-bottom: 8px; margin-bottom: 24px; }
.header-row h1 { border-bottom: none; padding-bottom: 0; margin-bottom: 0; flex: 1; min-width: 200px; }
.message { margin-bottom: 16px; border-radius: 12px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
.message.user { background: var(--user-bg); border-left: 4px solid var(--user-border); }
.message.assistant { background: var(--card-bg); border-left: 4px solid var(--assistant-border); }
.message.tool-reply { background: #fff8e1; border-left: 4px solid #ff9800; }
.tool-reply .role-label { color: #e65100; }
.tool-reply .tool-result { background: transparent; padding: 0; margin: 0; }
.tool-reply .tool-result .truncatable.truncated::after { background: linear-gradient(to bottom, transparent, #fff8e1); }
.message-header { display: flex; justify-content: space-between; align-items: center; padding: 8px 16px; background: rgba(0,0,0,0.03); font-size: 0.85rem; }
.role-label { font-weight: 600; text-transform: uppercase; letter-spacing: 0.5px; }
.user .role-label { color: var(--user-border); }
time { color: var(--text-muted); font-size: 0.8rem; }
.timestamp-link { color: inherit; text-decoration: none; }
.timestamp-link:hover { text-decoration: underline; }
.message:target { animation: highlight 2s ease-out; }
@keyframes highlight { 0% { background-color: rgba(25, 118, 210, 0.2); } 100% { background-color: transparent; } }
.message-content { padding: 16px; }
.message-content p { margin: 0 0 12px 0; }
.message-content p:last-child { margin-bottom: 0; }
.thinking { background: var(--thinking-bg); border: 1px solid var(--thinking-border); border-radius: 8px; padding: 12px; margin: 12px 0; font-size: 0.9rem; color: var(--thinking-text); }
.thinking-label { font-size: 0.75rem; font-weight: 600; text-transform: uppercase; color: #f57c00; margin-bottom: 8px; }
.thinking p { margin: 8px 0; }
.assistant-text { margin: 8px 0; }
.tool-use { background: var(--tool-bg); border: 1px solid var(--tool-border); border-radius: 8px; padding: 12px; margin: 12px 0; }
.tool-header { font-weight: 600; color: var(--tool-border); margin-bottom: 8px; display: flex; align-items: center; gap: 8px; }
.tool-icon { font-size: 1.1rem; }
.tool-description { font-size: 0.9rem; color: var(--text-muted); margin-bottom: 8px; font-style: italic; }
.tool-result { background: var(--tool-result-bg); border-radius: 8px; padding: 12px; margin: 12px 0; }
.tool-result.tool-error { background: var(--tool-error-bg); }
.file-tool { border-radius: 8px; padding: 12px; margin: 12px 0; }
.write-tool { background: linear-gradient(135deg, #e3f2fd 0%, #e8f5e9 100%); border: 1px solid #4caf50; }
.edit-tool { background: linear-gradient(135deg, #fff3e0 0%, #fce4ec 100%); border: 1px solid #ff9800; }
.file-tool-header { font-weight: 600; margin-bottom: 4px; display: flex; align-items: center; gap: 8px; font-size: 0.95rem; }
.write-header { color: #2e7d32; }
.edit-header { color: #e65100; }
.file-tool-icon { font-size: 1rem; }
.file-tool-path { font-family: monospace; background: rgba(0,0,0,0.08); padding: 2px 8px; border-radius: 4px; }
.file-tool-fullpath { font-family: monospace; font-size: 0.8rem; color: var(--text-muted); margin-bottom: 8px; word-break: break-all; }
.file-content { margin: 0; }
.edit-section { display: flex; margin: 4px 0; border-radius: 4px; overflow: hidden; }
.edit-label { padding: 8px 12px; font-weight: bold; font-family: monospace; display: flex; align-items: flex-start; }
.edit-old { background: #fce4ec; }
.edit-old .edit-label { color: #b71c1c; background: #f8bbd9; }
.edit-old .edit-content { color: #880e4f; }
.edit-new { background: #e8f5e9; }
.edit-new .edit-label { color: #1b5e20; background: #a5d6a7; }
.edit-new .edit-content { color: #1b5e20; }
.edit-content { margin: 0; flex: 1; background: transparent; font-size: 0.85rem; }
.edit-replace-all { font-size: 0.75rem; font-weight: normal; color: var(--text-muted); }
.write-tool .truncatable.truncated::after { background: linear-gradient(to bottom, transparent, #e6f4ea); }
.edit-tool .truncatable.truncated::after { background: linear-gradient(to bottom, transparent, #fff0e5); }
.todo-list { background: linear-gradient(135deg, #e8f5e9 0%, #f1f8e9 100%); border: 1px solid #81c784; border-radius: 8px; padding: 12px; margin: 12px 0; }
.todo-header { font-weight: 600; color: #2e7d32; margin-bottom: 10px; display: flex; align-items: center; gap: 8px; font-size: 0.95rem; }
.todo-items { list-style: none; margin: 0; padding: 0; }
.todo-item { display: flex; align-items: flex-start; gap: 10px; padding: 6px 0; border-bottom: 1px solid rgba(0,0,0,0.06); font-size: 0.9rem; }
.todo-item:last-child { border-bottom: none; }
.todo-icon { flex-shrink: 0; width: 20px; height: 20px; display: flex; align-items: center; justify-content: center; font-weight: bold; border-radius: 50%; }
.todo-completed .todo-icon { color: #2e7d32; background: rgba(46, 125, 50, 0.15); }
.todo-completed .todo-content { color: #558b2f; text-decoration: line-through; }
.todo-in-progress .todo-icon { color: #f57c00; background: rgba(245, 124, 0, 0.15); }
.todo-in-progress .todo-content { color: #e65100; font-weight: 500; }
.todo-pending .todo-icon { color: #757575; background: rgba(0,0,0,0.05); }
.todo-pending .todo-content { color: #616161; }
pre { background: var(--code-bg); color: var(--code-text); padding: 12px; border-radius: 6px; overflow-x: auto; font-size: 0.85rem; line-height: 1.5; margin: 8px 0; white-space: pre-wrap; word-wrap: break-word; }
pre.json { color: #e0e0e0; }
code { background: rgba(0,0,0,0.08); padding: 2px 6px; border-radius: 4px; font-size: 0.9em; }
pre code { background: none; padding: 0; }
.user-content { margin: 0; }
.truncatable { position: relative; }
.truncatable.truncated .truncatable-content { max-height: 200px; overflow: hidden; }
.truncatable.truncated::after { content: ''; position: absolute; bottom: 32px; left: 0; right: 0; height: 60px; background: linear-gradient(to bottom, transparent, var(--card-bg)); pointer-events: none; }
.message.user .truncatable.truncated::after { background: linear-gradient(to bottom, transparent, var(--user-bg)); }
.message.tool-reply .truncatable.truncated::after { background: linear-gradient(to bottom, transparent, #fff8e1); }
.tool-use .truncatable.truncated::after { background: linear-gradient(to bottom, transparent, var(--tool-bg)); }
.tool-result .truncatable.truncated::after { background: linear-gradient(to bottom, transparent, var(--tool-result-bg)); }
.expand-btn { display: none; width: 100%; padding: 8px 16px; margin-top: 4px; background: rgba(0,0,0,0.05); border: 1px solid rgba(0,0,0,0.1); border-radius: 6px; cursor: pointer; font-size: 0.85rem; color: var(--text-muted); }
.expand-btn:hover { background: rgba(0,0,0,0.1); }
.truncatable.truncated .expand-btn, .truncatable.expanded .expand-btn { display: block; }
.pagination { display: flex; justify-content: center; gap: 8px; margin: 24px 0; flex-wrap: wrap; }
.pagination a, .pagination span { padding: 5px 10px; border-radius: 6px; text-decoration: none; font-size: 0.85rem; }
.pagination a { background: var(--card-bg); color: var(--user-border); border: 1px solid var(--user-border); }
.pagination a:hover { background: var(--user-bg); }
.pagination .current { background: var(--user-border); color: white; }
.pagination .disabled { color: var(--text-muted); border: 1px solid #ddd; }
.pagination .index-link { background: var(--user-border); color: white; }
details.continuation { margin-bottom: 16px; }
details.continuation summary { cursor: pointer; padding: 12px 16px; background: var(--user-bg); border-left: 4px solid var(--user-border); border-radius: 12px; font-weight: 500; color: var(--text-muted); }
details.continuation summary:hover { background: rgba(25, 118, 210, 0.15); }
details.continuation[open] summary { border-radius: 12px 12px 0 0; margin-bottom: 0; }
.index-item { margin-bottom: 16px; border-radius: 12px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1); background: var(--user-bg); border-left: 4px solid var(--user-border); }
.index-item a { display: block; text-decoration: none; color: inherit; }
.index-item a:hover { background: rgba(25, 118, 210, 0.1); }
.index-item-header { display: flex; justify-content: space-between; align-items: center; padding: 8px 16px; background: rgba(0,0,0,0.03); font-size: 0.85rem; }
.index-item-number { font-weight: 600; color: var(--user-border); }
.index-item-content { padding: 16px; }
.index-item-stats { padding: 8px 16px 12px 32px; font-size: 0.85rem; color: var(--text-muted); border-top: 1px solid rgba(0,0,0,0.06); }
.index-item-commit { margin-top: 6px; padding: 4px 8px; background: #fff3e0; border-radius: 4px; font-size: 0.85rem; color: #e65100; }
.index-item-commit code { background: rgba(0,0,0,0.08); padding: 1px 4px; border-radius: 3px; font-size: 0.8rem; margin-right: 6px; }
.commit-card { margin: 8px 0; padding: 10px 14px; background: #fff3e0; border-left: 4px solid #ff9800; border-radius: 6px; }
.commit-card a { text-decoration: none; color: #5d4037; display: block; }
.commit-card a:hover { color: #e65100; }
.commit-card-hash { font-family: monospace; color: #e65100; font-weight: 600; margin-right: 8px; }
.index-commit { margin-bottom: 12px; padding: 10px 16px; background: #fff3e0; border-left: 4px solid #ff9800; border-radius: 8px; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }
.index-commit a { display: block; text-decoration: none; color: inherit; }
.index-commit a:hover { background: rgba(255, 152, 0, 0.1); margin: -10px -16px; padding: 10px 16px; border-radius: 8px; }
.index-commit-header { display: flex; justify-content: space-between; align-items: center; font-size: 0.85rem; margin-bottom: 4px; }
.index-commit-hash { font-family: monospace; color: #e65100; font-weight: 600; }
.index-commit-msg { color: #5d4037; }
.index-item-long-text { margin-top: 8px; padding: 12px; background: var(--card-bg); border-radius: 8px; border-left: 3px solid var(--assistant-border); }
.index-item-long-text .truncatable.truncated::after { background: linear-gradient(to bottom, transparent, var(--card-bg)); }
.index-item-long-text-content { color: var(--text-color); }
#search-box { display: none; align-items: center; gap: 8px; }
#search-box input { padding: 6px 12px; border: 1px solid var(--assistant-border); border-radius: 6px; font-size: 16px; width: 180px; }
#search-box button, #modal-search-btn, #modal-close-btn { background: var(--user-border); color: white; border: none; border-radius: 6px; padding: 6px 10px; cursor: pointer; display: flex; align-items: center; justify-content: center; }
#search-box button:hover, #modal-search-btn:hover { background: #1565c0; }
#modal-close-btn { background: var(--text-muted); margin-left: 8px; }
#modal-close-btn:hover { background: #616161; }
#search-modal[open] { border: none; border-radius: 12px; box-shadow: 0 4px 24px rgba(0,0,0,0.2); padding: 0; width: 90vw; max-width: 900px; height: 80vh; max-height: 80vh; display: flex; flex-direction: column; }
#search-modal::backdrop { background: rgba(0,0,0,0.5); }
.search-modal-header { display: flex; align-items: center; gap: 8px; padding: 16px; border-bottom: 1px solid var(--assistant-border); background: var(--bg-color); border-radius: 12px 12px 0 0; }
.search-modal-header input { flex: 1; padding: 8px 12px; border: 1px solid var(--assistant-border); border-radius: 6px; font-size: 16px; }
#search-status { padding: 8px 16px; font-size: 0.85rem; color: var(--text-muted); border-bottom: 1px solid rgba(0,0,0,0.06); }
#search-results { flex: 1; overflow-y: auto; padding: 16px; }
.search-result { margin-bottom: 16px; border-radius: 8px; overflow: hidden; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
.search-result a { display: block; text-decoration: none; color: inherit; }
.search-result a:hover { background: rgba(25, 118, 210, 0.05); }
.search-result-page { padding: 6px 12px; background: rgba(0,0,0,0.03); font-size: 0.8rem; color: var(--text-muted); border-bottom: 1px solid rgba(0,0,0,0.06); }
.search-result-content { padding: 12px; }
.search-result mark { background: #fff59d; padding: 1px 2px; border-radius: 2px; }
@media (max-width: 600px) { body { padding: 8px; } .message, .index-item { border-radius: 8px; } .message-content, .index-item-content { padding: 12px; } pre { font-size: 0.8rem; padding: 8px; } #search-box input { width: 120px; } #search-modal[open] { width: 95vw; height: 90vh; } }
</style>
</head>
<body>
    <div class="container">
        <h1><a href="index.html" style="color: inherit; text-decoration: none;">Claude Code transcript</a> - page 2/2</h1>
        

<div class="pagination">
<a href="index.html" class="index-link">Index</a>
<a href="page-001.html">&larr; Prev</a>
<a href="page-001.html">1</a>
<span class="current">2</span>
<span class="disabled">Next &rarr;</span>
</div>

        
<div class="message user" id="msg-2025-12-13T02-12-28-528Z"><div class="message-header"><span class="role-label">User</span><a href="#msg-2025-12-13T02-12-28-528Z" class="timestamp-link"><time datetime="2025-12-13T02:12:28.528Z" data-timestamp="2025-12-13T02:12:28.528Z">2025-12-13T02:12:28.528Z</time></a></div><div class="message-content">
<div class="user-content"><p>can you save our work here as markdown documents. i am going to close this session and return to this project at a future date</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-12-34-984Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-12-34-984Z" class="timestamp-link"><time datetime="2025-12-13T02:12:34.984Z" data-timestamp="2025-12-13T02:12:34.984Z">2025-12-13T02:12:34.984Z</time></a></div><div class="message-content">
<div class="thinking"><div class="thinking-label">Thinking</div><p>The user wants me to save our conversation/analysis about prevalence filtering in microbiome/virome research as markdown documents. This is a documentation task, so I should create organized markdown files that capture the key insights, methods discussed, and recommendations.</p>
<p>Let me think about how to organize this:</p>
<ol>
<li>A main summary document with key findings</li>
<li>A detailed methods comparison document</li>
<li>A practical recommendations/decision guide</li>
<li>A resources/references document</li>
</ol>
<p>I should check what directory we're in and create these files appropriately.</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-12-35-673Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-12-35-673Z" class="timestamp-link"><time datetime="2025-12-13T02:12:35.673Z" data-timestamp="2025-12-13T02:12:35.673Z">2025-12-13T02:12:35.673Z</time></a></div><div class="message-content">
<div class="assistant-text"><p>I'll create a comprehensive set of markdown documents capturing our discussion about prevalence filtering in microbiome/omics analysis.</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-12-36-120Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-12-36-120Z" class="timestamp-link"><time datetime="2025-12-13T02:12:36.120Z" data-timestamp="2025-12-13T02:12:36.120Z">2025-12-13T02:12:36.120Z</time></a></div><div class="message-content">
<div class="tool-use bash-tool" data-tool-id="toolu_01NPFmBNzbYmPQpjF2NrQLqa">
<div class="tool-header"><span class="tool-icon">$</span> Bash</div>
<div class="tool-description">Check current working directory</div><div class="truncatable"><div class="truncatable-content"><pre class="bash-command">pwd</pre></div><button class="expand-btn">Show more</button></div>
</div></div></div>
<div class="message tool-reply" id="msg-2025-12-13T02-12-36-251Z"><div class="message-header"><span class="role-label">Tool reply</span><a href="#msg-2025-12-13T02-12-36-251Z" class="timestamp-link"><time datetime="2025-12-13T02:12:36.251Z" data-timestamp="2025-12-13T02:12:36.251Z">2025-12-13T02:12:36.251Z</time></a></div><div class="message-content"><div class="tool-result"><div class="truncatable"><div class="truncatable-content"><pre>/Users/scotthandley/Code/smart_prev_filter</pre></div><button class="expand-btn">Show more</button></div></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-12-42-354Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-12-42-354Z" class="timestamp-link"><time datetime="2025-12-13T02:12:42.354Z" data-timestamp="2025-12-13T02:12:42.354Z">2025-12-13T02:12:42.354Z</time></a></div><div class="message-content">
<div class="thinking"><div class="thinking-label">Thinking</div><p>Perfect - we're in a directory called "smart_prev_filter" which is very appropriate for this content. I'll create several markdown files:</p>
<ol>
<li>README.md - Overview and executive summary</li>
<li>current_methods_review.md - Detailed review of existing methods</li>
<li>critical_analysis.md - Our critical analysis of whether this is a real problem</li>
<li>practical_recommendations.md - Decision trees and practical guidance</li>
<li>references.md - All the sources we found</li>
</ol>
<p>Let me create these files.</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-13-35-005Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-13-35-005Z" class="timestamp-link"><time datetime="2025-12-13T02:13:35.005Z" data-timestamp="2025-12-13T02:13:35.005Z">2025-12-13T02:13:35.005Z</time></a></div><div class="message-content"><div class="file-tool write-tool" data-tool-id="toolu_014d6i7sY2VrUGMgcx5iMx2B">
<div class="file-tool-header write-header"><span class="file-tool-icon">üìù</span> Write <span class="file-tool-path">README.md</span></div>
<div class="file-tool-fullpath">/Users/scotthandley/Code/smart_prev_filter/README.md</div>
<div class="truncatable"><div class="truncatable-content"><pre class="file-content"># Smart Prevalence Filtering for Microbiome/Virome Data

## Overview

This repository documents research into systematic approaches for prevalence and abundance filtering in omics data (microbiome, virome, transcriptomics). Traditional filtering uses arbitrary &#34;community standards&#34; (e.g., 3% prevalence, 1% abundance for bacterial microbiome), but these lack scientific justification and can remove biologically important signal.

## The Core Problem

**Current practice**: Apply global prevalence/abundance thresholds before differential abundance (DA) testing
- Reduces multiple testing burden (fewer features ‚Üí lower FDR penalty)
- Removes &#34;noise&#34; features
- Improves computational efficiency

**Key issues**:
1. **Arbitrary thresholds** lack theoretical foundation
2. **Context-dependent needs** - sparse vs dense datasets need different strategies
3. **Loss of discriminative signal** - low-abundance but perfectly prevalant features get removed
4. **P-hacking vulnerability** - tuning filters to achieve p &lt; 0.05
5. **Denominator problem** - global filtering removes region/group-specific taxa

**Example**: A feature with only 1 read per sample but ALWAYS present in diseased group (prevalence association) would be removed by standard abundance filtering, despite being perfectly discriminative.

## Critical Question

**Is optimal filtering optimization even necessary, or do modern statistical methods already handle this?**

After extensive literature review and critical analysis, the answer is nuanced:

### The Problem is REAL but TRANSITIONING

**Serious aspects**:
- Affects reproducibility across studies
- Can lose biologically important signal
- Community standards lack justification
- Creates p-hacking opportunities

**Less serious than it seems**:
- Modern methods increasingly don&#39;t require filtering (MaAsLin3, regularization, adaptive FDR)
- Results generally robust to reasonable filtering choices
- Field is solving this via method development, not filtering optimization

### Verdict: Need Better TOOLS and WORKFLOWS, Not Complex Theory

The field needs:
1. **Diagnostic packages** to characterize data and guide method selection
2. **Sensitivity analysis automation** to assess robustness
3. **Method selection guidance** based on data characteristics
4. **Transparency standards** for reporting filtering choices

NOT:
- Bayesian threshold optimization (intellectually elegant, practically overkill)
- Another differential abundance method
- Complex statistical theory

## Key Insights

### Modern Methods That Don&#39;t Require Filtering

1. **MaAsLin3 (Dec 2024)**: Models prevalence as outcome, not filter criterion
   - Tests prevalence and abundance associations separately
   - 77% of IBD associations were prevalence, not abundance
   - **But**: Has FDR inflation issues with dense signals and compositional effects

2. **Regularization methods**: LASSO, elastic net, horseshoe priors automatically shrink noise to zero

3. **Adaptive FDR**: IHW, AdaFDR increase power 25-68% by using covariates to weight tests

4. **Two-part models**: Explicitly model zeros (prevalence) separately from abundance

### When Filtering IS Still Needed

**Quality Control (always appropriate)**:
- Remove contaminants (decontam, SourceTracker)
- Remove features with extreme sparsity (&lt;2 samples)
- Batch effect correction

**Statistical filtering (context-dependent)**:
- Computational efficiency (large datasets)
- Unstable effect estimates (very rare features)
- Interpretability (reduce to meaningful signal)
- Method-specific requirements (ALDEx2, ANCOM-BC)

### Data-Driven Filtering Methods

1. **PERFect (2019)**: Permutation testing, minimizes covariance loss
2. **Mutual Information (2022)**: Threshold-free, detects low-abundance true taxa
   - Reduced 431 ASVs to 57 in dairy calf study (76% contaminants)
3. **Hyperparameter tuning**: Treat thresholds as ML hyperparameters

## Major Findings from Literature

### Differential Abundance Method Comparison

**2024 Benchmark** ([Realistic benchmark study](https://pmc.ncbi.nlm.nih.gov/articles/PMC11423519/)):
&gt; &#34;Only classic statistical methods (linear models, Wilcoxon test, t-test), limma, and fastANCOM properly control false discoveries&#34;

**Key findings**:
- **MaAsLin2** has FDR inflation with dense signals and compositional effects
- **ANCOM-BC and LinDA** perform best overall
- **LinDA** is 100-1000√ó faster than ANCOM-BC
- **ALDEx2** most conservative (strong FDR control, lower power)
- Different methods produce &#34;drastically different&#34; results

### When NOT to Use MaAsLin

Despite its popularity, MaAsLin2/3 has limitations:

‚ùå Dense signal scenarios (FDR inflation)
‚ùå Strong compositional effects (poor FDR control)
‚ùå Maximum sensitivity needed (too conservative)
‚ùå Simple univariate comparisons (classic methods better)
‚ùå Very large datasets (speed issues)

‚úÖ Complex covariates with random effects
‚úÖ Distinguishing prevalence vs abundance
‚úÖ Longitudinal/clustered data
‚úÖ Can tolerate conservative approach

## Practical Recommendations

### Decision Tree

```
Q: Simple case vs control?
YES ‚Üí Wilcoxon or limma
NO  ‚Üí Continue

Q: Dense signals (many DA features)?
YES ‚Üí LinDA or ANCOM-BC2
NO  ‚Üí Continue

Q: Compositional bias concern?
YES ‚Üí ALDEx2 or ANCOM-BC
NO  ‚Üí Continue

Q: Distinguish prevalence vs abundance?
YES ‚Üí MaAsLin3 or two-part models
NO  ‚Üí Continue

Q: Need speed?
YES ‚Üí LinDA
NO  ‚Üí ANCOM-BC2 (most balanced)
```

### Always Do

1. **Quality control filtering** (contaminants, extreme sparsity)
2. **Sensitivity analysis** across methods and thresholds
3. **Report concordance/discordance** between approaches
4. **Visualize** (volcano plots, effect size distributions)
5. **Pre-specify** filtering strategy (avoid p-hacking)

## Research Gaps and Opportunities

### High-Value Software Development

**Diagnostic package** (most needed):
```r
library(smartfilter)  # doesn&#39;t exist yet

# Comprehensive diagnostics
diagnostics &lt;- diagnose_filtering(
  data = phyloseq_obj,
  thresholds = expand.grid(...),
  outcome = metadata$disease,
  covariates = ~ country + treatment + (1|PID)
)

# Interactive visualization
plot(diagnostics, type = &#34;sparsity&#34;)
plot(diagnostics, type = &#34;filtering_impact&#34;)
plot(diagnostics, type = &#34;covariance_loss&#34;)
plot(diagnostics, type = &#34;mutual_information&#34;)

# Method selection guidance
recommendations &lt;- suggest_strategy(diagnostics)

# Automated sensitivity analysis
sensitivity &lt;- test_robustness(diagnostics, methods = c(&#34;linda&#34;, &#34;ancombc2&#34;))
```

### Lower Priority: Methodological Research

- Bayesian threshold optimization (intellectually interesting, practically overkill)
- New differential abundance methods (already too many)
- Covariate-aware hierarchical filtering (complex, unclear benefit)

## Repository Structure

- `README.md` - This overview
- `current_methods_review.md` - Detailed review of existing approaches
- `critical_analysis.md` - Deep analysis of whether this is a real problem
- `practical_recommendations.md` - Decision trees and implementation guidance
- `references.md` - Comprehensive bibliography with links

## Conclusion

The prevalence filtering problem is **real but being solved** through better statistical methods that don&#39;t require filtering, rather than through filtering optimization. The most valuable contribution would be **practical diagnostic tools** that help researchers:

1. Characterize their data
2. Choose appropriate methods
3. Assess robustness
4. Report transparently

This is a **tooling and workflow problem**, not a statistical theory problem.

## Key References

- [MaAsLin3 (Dec 2024)](https://pmc.ncbi.nlm.nih.gov/articles/PMC11661281/)
- [Realistic DA benchmark (2024)](https://pmc.ncbi.nlm.nih.gov/articles/PMC11423519/)
- [Comprehensive DA evaluation (2022)](https://link.springer.com/article/10.1186/s40168-022-01320-0)
- [MI-based filtering (2022)](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-022-04919-0)
- [PERFect method (2019)](https://academic.oup.com/biostatistics/article/20/4/615/5039878)
- [IHW adaptive FDR (2016)](https://pmc.ncbi.nlm.nih.gov/articles/PMC4930141/)

---

**Status**: Initial research and critical analysis complete (2025-01-12)
**Next steps**: Prototype diagnostic package, validate on real datasets
</pre></div><button class="expand-btn">Show more</button></div>
</div></div></div>
<div class="message tool-reply" id="msg-2025-12-13T02-13-35-034Z"><div class="message-header"><span class="role-label">Tool reply</span><a href="#msg-2025-12-13T02-13-35-034Z" class="timestamp-link"><time datetime="2025-12-13T02:13:35.034Z" data-timestamp="2025-12-13T02:13:35.034Z">2025-12-13T02:13:35.034Z</time></a></div><div class="message-content"><div class="tool-result"><div class="truncatable"><div class="truncatable-content"><pre>File created successfully at: /Users/scotthandley/Code/smart_prev_filter/README.md</pre></div><button class="expand-btn">Show more</button></div></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-13-39-651Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-13-39-651Z" class="timestamp-link"><time datetime="2025-12-13T02:13:39.651Z" data-timestamp="2025-12-13T02:13:39.651Z">2025-12-13T02:13:39.651Z</time></a></div><div class="message-content">
<div class="thinking"><div class="thinking-label">Thinking</div><p>Good, now let me create the detailed methods review document.</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-15-15-057Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-15-15-057Z" class="timestamp-link"><time datetime="2025-12-13T02:15:15.057Z" data-timestamp="2025-12-13T02:15:15.057Z">2025-12-13T02:15:15.057Z</time></a></div><div class="message-content"><div class="file-tool write-tool" data-tool-id="toolu_01HFiwD7JX5LArA6aXjcDUfd">
<div class="file-tool-header write-header"><span class="file-tool-icon">üìù</span> Write <span class="file-tool-path">current_methods_review.md</span></div>
<div class="file-tool-fullpath">/Users/scotthandley/Code/smart_prev_filter/current_methods_review.md</div>
<div class="truncatable"><div class="truncatable-content"><pre class="file-content"># Current Methods Review: Prevalence Filtering and Differential Abundance

## Table of Contents

1. [Systematic Filtering Approaches](#systematic-filtering-approaches)
2. [Study-Design Aware Methods](#study-design-aware-methods)
3. [Bayesian Variable Selection](#bayesian-variable-selection)
4. [Differential Abundance Methods](#differential-abundance-methods)
5. [Information-Theoretic Approaches](#information-theoretic-approaches)
6. [Adaptive FDR Methods](#adaptive-fdr-methods)

---

## Systematic Filtering Approaches

### PERFect (PERmutation Filtering test)

**Publication**: [Biostatistics 2019](https://academic.oup.com/biostatistics/article/20/4/615/5039878)

**Key innovation**: Data-driven threshold determination via permutation testing

**Method**:
- Implements statistical significance thresholds rather than arbitrary cutoffs
- Performs dimension reduction consistent with minimal total covariance loss
- Identifies optimal subset of taxa that contribute most to total covariance
- Provides visualization of relationship between taxa p-values and filtering loss

**Advantages**:
- Statistically principled
- Avoids arbitrary hard thresholds
- Visualizes filtering impact
- Easy to use

**When to use**:
- When you need objective filtering criteria
- Before downstream analyses that benefit from dimension reduction
- When you want to quantify information loss from filtering

### Mutual Information (MI) Based Filtering

**Publication**: [BMC Bioinformatics 2022](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-022-04919-0)

**Key innovation**: Threshold-free filtering using information theory and graph theory

**Method**:
- Uses mutual information to identify contaminants vs true taxa
- Network-based approach leverages co-occurrence patterns
- Does not require arbitrary threshold selection

**Advantages**:
- **No arbitrary thresholds**
- **Can detect true taxa with low abundance** - critical for rare but important features
- Removes contaminants effectively

**Real-world performance**:
- Dairy calf gut microbiome: 431 ASVs ‚Üí 57 ASVs (76% identified as contamination)
- Makes downstream analyses more interpretable

**2024 update**: [Comparative analysis](https://link.springer.com/article/10.1186/s12859-024-05883-7) showed MI uncovers complex relationships missed by correlation alone

**When to use**:
- When you want to preserve low-abundance but biologically important taxa
- Contaminant removal (quality control)
- When standard prevalence thresholds seem too arbitrary

---

## Study-Design Aware Methods

### ANCOM-BC2 (Analysis of Compositions of Microbiomes with Bias Correction 2)

**Publication**: [Nature Methods 2024](https://www.nature.com/articles/s41592-023-02092-7)

**Key innovation**: Multigroup analysis with covariate adjustments and repeated measures

**Method**:
- General framework for complex study designs
- Handles covariates: `~ country + disease + treatment + (1|PID)`
- Controls FDR or mixed directional FDR (mdFDR)
- Includes sensitivity analysis for pseudo-count choices (0.1, 0.5, 1.0)

**Advantages**:
- Handles complex designs (multigroup, longitudinal, covariates)
- Explicit bias correction
- Sensitivity analysis for zero handling
- More efficient than pairwise comparisons

**Limitations**:
- Computationally intensive (slow with many features)
- FDR inflation at small sample sizes or strong compositional effects
- Does not do group-specific filtering

**When to use**:
- Complex study designs with multiple groups
- Need covariate adjustment
- Longitudinal/repeated measures data
- Can tolerate computational cost

### MaAsLin3 (Microbiome Multivariable Association with Linear Models 3)

**Publication**: [PMC Dec 2024](https://pmc.ncbi.nlm.nih.gov/articles/PMC11661281/)

**Key innovation**: Tests prevalence and abundance associations separately

**Method**:
- Generalized linear models with covariate support
- Random effects for longitudinal/clustered data
- **Prevalence testing**: Models presence/absence as outcome
- **Abundance testing**: Models non-zero abundances
- Requires sequencing depth as covariate for prevalence testing

**Advantages**:
- Distinguishes prevalence vs abundance associations (critical!)
- Supports complex formulas: `~ country + disease + treatment + (1|PID)`
- Flexible transformations (TSS + log is default)
- 77% of IBD associations were prevalence, not abundance

**Limitations (CRITICAL)**:
- **FDR inflation with dense signals**
- **Poor FDR control under strong compositional effects**
- **Low power** compared to some alternatives
- **Too conservative** in many scenarios
- NOT recommended for simple case vs control (classic methods better)

**Performance metrics**:
- Precision improvement: +0.29 over MaAsLin2
- But: Multiple benchmarks show FDR issues

**When to use**:
- Need to distinguish prevalence vs abundance
- Complex covariates with random effects
- Can tolerate conservative approach
- NOT dense signals, NOT strong compositional effects

**When NOT to use**:
- Simple case vs control (use Wilcoxon, limma instead)
- Dense signals (use LinDA, ANCOM-BC2)
- Maximum sensitivity needed
- Strong compositional bias

### LinDA (Linear Models for Differential Abundance)

**Publication**: [Genome Biology 2022](https://link.springer.com/article/10.1186/s13059-022-02655-5)

**Key innovation**: Fast compositional-aware linear models

**Method**:
- Linear models with compositional adjustment
- Similar to ANCOM-II model but addresses multigroup testing
- Handles covariates efficiently

**Advantages**:
- **100-1000√ó faster than ANCOM-BC**
- Competitive performance with ANCOM-BC
- Good FDR control in most settings
- Handles covariates

**Limitations**:
- Spearman correlation test and MaAsLin2-like approaches have FDR inflation with dense continuous covariates

**When to use**:
- Large datasets requiring speed
- Multigroup comparisons with covariates
- Alternative to ANCOM-BC when computational cost is prohibitive

### LDM (Linear Decomposition Model)

**Publication**: [PMC 2021](https://pmc.ncbi.nlm.nih.gov/articles/PMC8453243/)

**Key innovation**: Distance-based testing with covariate adjustment

**Method**:
- Global tests of microbiome effects
- Individual feature tests with FDR control
- Adjusts for confounding covariates
- Handles clustered/longitudinal data (repeated measurements)
- Connection to distance-based ordination

**Extensions**:
- [Rarefaction-based extension](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8289387/) for presence-absence testing

**Advantages**:
- Adjusts for covariates in distance-based analyses
- Handles longitudinal data
- Both global and feature-level tests

**When to use**:
- Distance-based analyses (beta diversity)
- Longitudinal/clustered designs
- Want both global and specific tests

---

## Bayesian Variable Selection

### Spike-and-Slab Priors

**General approach**: Probabilistic feature selection via MCMC

**Model**:
```
Œ≤_j ~ œÄ_j √ó N(0, œÉ¬≤_slab) + (1 - œÄ_j) √ó Œ¥_0(spike)
œÄ_j ~ Beta(a, b)
```

**Publications**:
- [Zero-inflated models (2020)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7308073/)
- [VBayesMM neural network (2024)](https://academic.oup.com/bib/article/26/4/bbaf300/8185645)

**Method**:
- MCMC samples which taxa to include (œÄ_j) and their effects (Œ≤_j)
- Probabilistic filtering - posterior probabilities of inclusion
- Analogous to phylogenetic MCMC exploring tree space

**Advantages**:
- Principled uncertainty quantification
- Incorporates prior knowledge
- Handles high-dimensional sparse data

**Limitations**:
- Feature-level selection, not threshold estimation
- Computationally expensive
- Complex to implement

**When to use**:
- Need uncertainty quantification on feature selection
- High-dimensional microbiome data
- Can tolerate computational cost

### Bayesian Compositional Models

**Publications**:
- [BCGLM (Statistics in Medicine 2024)](https://onlinelibrary.wiley.com/doi/10.1002/sim.9946)
- [BRACE (2024 preprint)](https://arxiv.org/html/2406.01557)
- [Variable shrinkage (2024)](https://pmc.ncbi.nlm.nih.gov/articles/PMC11470902/)

**Key innovations**:
- Structured regularized horseshoe priors
- Phylogenetically-structured shrinkage
- Spiked Dirichlet process for functional grouping
- Hamiltonian Monte Carlo via Stan

**Advantages**:
- Borrows information across phylogenetically related taxa
- Sparse feature selection with shared impacts
- Accounts for compositionality

**When to use**:
- Phylogenetic structure important
- Need to identify functionally similar taxa
- Bayesian framework preferred

### BORAL (Bayesian Ordination and Regression AnaLysis)

**Publication**: [Methods in Ecology and Evolution 2016](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12514)

**Key innovation**: Stochastic Search Variable Selection (SSVS) via JAGS

**Method**:
- MCMC samples indicator variables for including/excluding species
- Latent variables for ordination
- Can incorporate species traits

**Advantages**:
- Combines ordination with variable selection
- Posterior probabilities of inclusion
- Handles correlated species

**When to use**:
- Want ordination AND feature selection
- Ecological/species distribution modeling
- Can work with JAGS

---

## Differential Abundance Methods

### Benchmark Results Summary

**2024 Realistic Benchmark** ([PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC11423519/)):

**Proper FDR control**:
- Classic methods: Linear models, Wilcoxon, t-test ‚úì
- limma ‚úì
- fastANCOM ‚úì
- MaAsLin2 ‚úó (FDR inflation in many scenarios)

**Key findings**:
- &#34;Tight error control is critical&#34;
- &#34;Unsatisfactory performance of many DA methods&#34;
- &#34;Persistent danger of unchecked confounding&#34;
- Confounder adjustment can effectively mitigate issues

**2022 Nature Communications** ([Link](https://www.nature.com/articles/s41467-022-28034-z)):
- 14 methods tested on 38 datasets
- Methods produce &#34;drastically different&#34; results
- Results depend on pre-processing
- ALDEx2 and MaAsLin2 among most consistent

### Method-Specific Performance

**ALDEx2**:
- Most conservative (strong FDR control)
- Low power, especially for rare taxa
- Best at small sample sizes
- Explicit compositional correction (CLR transformation)

**ANCOM-BC**:
- Best overall performance (with LinDA)
- Explicit bias correction
- Very slow (100-1000√ó slower than LinDA)
- FDR inflation at small n or strong compositional effects

**LinDA**:
- Best overall performance (with ANCOM-BC)
- 100-1000√ó faster than ANCOM-BC
- Good FDR control in most settings
- FDR issues with dense continuous covariates

**MaAsLin2/3**:
- Flexible covariate support
- Random effects
- FDR inflation with dense signals
- FDR inflation with compositional effects
- Low power (conservative)
- Found no significant features in 6/8 false positive tests

**DESeq2/edgeR**:
- High power
- Severe FDR inflation in most settings
- Not recommended for microbiome (designed for RNA-seq)

**Wilcoxon/Classic tests**:
- Proper FDR control (2024 benchmark)
- Simple, fast
- Good for univariate comparisons
- Limited to simple designs

---

## Information-Theoretic Approaches

### Mutual Information

**See detailed section above**

Additional applications:
- Network inference
- Co-occurrence pattern detection
- Feature importance ranking

### Entropy-Based Selection

**Concept**: Features with high entropy (uniformly noisy) can be filtered

**Approach**:
- Calculate Shannon entropy per feature
- Low entropy in discriminative direction = informative
- High uniform entropy = noise

### Information Gain

**Concept**: How much does including a feature reduce uncertainty about outcome?

**Approach**:
- IG(Feature) = H(Outcome) - H(Outcome | Feature)
- Rank features by information gain
- Filter features below threshold

**Advantages**:
- Objective criterion independent of p-values
- Addresses p-hacking concerns

### Minimum Description Length (MDL)

**Concept**: Choose simplest model that adequately describes data

**Application to filtering**:
- Balance model complexity (# features) vs fit
- Natural Occam&#39;s razor
- Penalizes overfitting

---

## Adaptive FDR Methods

### IHW (Independent Hypothesis Weighting)

**Publication**: [PMC 2016](https://pmc.ncbi.nlm.nih.gov/articles/PMC4930141/)

**Key innovation**: Use covariates to weight hypotheses, increasing power

**Method**:
- Splits hypotheses into strata based on covariate
- Learns optimal weights per stratum via cross-validation
- Covariates must be independent of p-values under null

**Performance**:
- 25-68% power increase over Benjamini-Hochberg
- Maintains FDR control
- Available as Bioconductor package

**Example covariates**:
- Mean expression level (RNA-seq)
- Mean abundance (microbiome)
- Phylogenetic depth
- Functional annotation

**When to use**:
- High-dimensional testing (thousands of features)
- Informative covariates available
- Want maximum power while controlling FDR

### AdaFDR

**Publication**: [Nature Communications 2019](https://www.nature.com/articles/s41467-019-11247-0)

**Key innovation**: Adaptive weighting with covariate information

**Performance**:
- 32% more associations than BH on GTEx eQTL data
- Fast covariate-adaptive method
- Can improve detection power significantly

### StructFDR

**Application**: Microbiome-wide multiple testing

**Concept**: Use domain knowledge (phylogenetic structure, pathways) to improve power

**Similar approaches**:
- GSEA for gene pathway analysis
- TORUS for eQTL studies

---

## Two-Part Models for Longitudinal Data

### ZIBR (Zero-Inflated Beta Regression)

**Publication**: [Bioinformatics 2016](https://academic.oup.com/bioinformatics/article/32/17/2611/2450750)

**Method**:
- **Part 1**: Logistic regression for presence/absence (prevalence)
- **Part 2**: Beta regression for non-zero abundance
- Random effects in both parts for repeated measurements

**Advantages**:
- Explicitly models zeros (prevalence) separately
- Handles longitudinal data naturally
- No need for arbitrary filtering

### ZIGMM (Zero-Inflated Gaussian Mixed Models)

**Publication**: [PLOS ONE 2020](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0242073)

**Method**:
- Various fixed and random effect structures
- Accounts for within-subject correlations
- Handles zero-inflation explicitly

### GLMMs for Microbiome

**Packages**: glmmTMB, GLMMadaptive, NBZIMM

**Approaches**:
- Zero-inflated negative binomial mixed models
- Over-dispersed count data
- Longitudinal correlations

**When to use two-part models**:
- Longitudinal/repeated measures
- Care about prevalence AND abundance
- Want explicit zero modeling vs filtering

---

## Summary Recommendations by Use Case

| Use Case | Recommended Method | Alternative | Avoid |
|----------|-------------------|-------------|-------|
| **Simple case vs control** | Wilcoxon, limma, fastANCOM | ALDEx2 | MaAsLin2, DESeq2 |
| **Dense signals** | LinDA, ANCOM-BC2 | fastANCOM | MaAsLin2 |
| **Small sample size** | ALDEx2, Wilcoxon | limma | DESeq2, edgeR |
| **Complex covariates** | ANCOM-BC2, LinDA | MaAsLin3 | Simple tests |
| **Longitudinal** | ANCOM-BC2, two-part models | MaAsLin3 | Cross-sectional methods |
| **Prevalence vs abundance** | MaAsLin3, two-part models | Separate tests | Standard DA |
| **Compositional bias** | ALDEx2, ANCOM-BC | LinDA | MaAsLin2 |
| **Need speed** | LinDA, Wilcoxon | fastANCOM | ANCOM-BC |
| **Quality control filtering** | MI-based, PERFect | decontam | Arbitrary thresholds |
| **Maximum power** | IHW + LinDA | AdaFDR + ANCOM-BC | Conservative methods |

---

## Key Takeaways

1. **No perfect method** - choice depends on data characteristics and research question
2. **FDR control is critical** - many popular methods have inflation issues
3. **MaAsLin is NOT always the answer** - serious limitations despite popularity
4. **Filtering alternatives** - MI-based and PERFect for data-driven thresholds
5. **Prevalence matters** - 77% of associations may be prevalence, not abundance
6. **Speed matters** - LinDA competitive with ANCOM-BC but 100-1000√ó faster
7. **Classic methods work** - Wilcoxon and limma have best FDR control for simple comparisons
8. **Sensitivity analysis required** - methods disagree, report concordance

---

## References

See `references.md` for complete bibliography with links.
</pre></div><button class="expand-btn">Show more</button></div>
</div></div></div>
<div class="message tool-reply" id="msg-2025-12-13T02-15-15-078Z"><div class="message-header"><span class="role-label">Tool reply</span><a href="#msg-2025-12-13T02-15-15-078Z" class="timestamp-link"><time datetime="2025-12-13T02:15:15.078Z" data-timestamp="2025-12-13T02:15:15.078Z">2025-12-13T02:15:15.078Z</time></a></div><div class="message-content"><div class="tool-result"><div class="truncatable"><div class="truncatable-content"><pre>File created successfully at: /Users/scotthandley/Code/smart_prev_filter/current_methods_review.md</pre></div><button class="expand-btn">Show more</button></div></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-15-21-670Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-15-21-670Z" class="timestamp-link"><time datetime="2025-12-13T02:15:21.670Z" data-timestamp="2025-12-13T02:15:21.670Z">2025-12-13T02:15:21.670Z</time></a></div><div class="message-content">
<div class="thinking"><div class="thinking-label">Thinking</div><p>Now let me create the critical analysis document that captures our deep thinking about whether this is really a serious problem.</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-17-04-842Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-17-04-842Z" class="timestamp-link"><time datetime="2025-12-13T02:17:04.842Z" data-timestamp="2025-12-13T02:17:04.842Z">2025-12-13T02:17:04.842Z</time></a></div><div class="message-content"><div class="file-tool write-tool" data-tool-id="toolu_01Waw6gTAZSQW99zQZ41MNrP">
<div class="file-tool-header write-header"><span class="file-tool-icon">üìù</span> Write <span class="file-tool-path">critical_analysis.md</span></div>
<div class="file-tool-fullpath">/Users/scotthandley/Code/smart_prev_filter/critical_analysis.md</div>
<div class="truncatable"><div class="truncatable-content"><pre class="file-content"># Critical Analysis: Is Prevalence Filtering Optimization Really Necessary?

## The Central Question

**&#34;Is optimal filtering really that serious of an issue, or are modern models good enough that requiring an optimality criterion is overkill?&#34;**

This document captures a systematic critical analysis of whether prevalence filtering optimization is:
1. A real problem worth solving
2. Already solved by modern methods
3. Better addressed through different approaches

---

## The Phylogenetic Analogy

### Parallels to Phylogenetic Inference

The filtering problem shares conceptual similarities with phylogenetic tree inference:

**Phylogenetic Inference**:
- **Parameter space**: Tree topology + branch lengths + substitution model parameters
- **Optimization**: Maximize P(sequences | tree, model)
- **Method**: MCMC explores posterior P(tree, parameters | data)
- **Output**: Posterior distribution of trees, credible intervals
- **Model selection**: Compare via Bayes factors, AIC, BIC

**Filtering Optimization (envisioned)**:
- **Parameter space**: Prevalence thresholds + abundance thresholds + model parameters
- **Optimization**: Maximize P(outcome | filtered_features, covariates, model)
- **Method**: MCMC explores posterior P(thresholds, parameters | data)
- **Output**: Posterior distribution of optimal thresholds
- **Model selection**: Compare filtering strategies via marginal likelihood, WAIC

### Why This Analogy Resonates

Just as phylogenetic inference moves beyond arbitrary distance metrics to model-based likelihood approaches, filtering could move beyond arbitrary thresholds to model-based threshold estimation.

**Key insight**: In phylogenetics, we don&#39;t pre-filter &#34;noisy sites&#34; arbitrarily - we model them explicitly. Same principle could apply to microbiome features.

### Why This Analogy Breaks Down

**Critical difference**:
- Phylogenetics: Evaluate P(sequences | tree) - straightforward likelihood
- Filtering: Evaluate P(outcome | filtered_data(threshold), model) - requires fitting downstream model at each MCMC iteration

**Computational barrier**: With thousands of taxa and complex models, this becomes prohibitively expensive.

**Philosophical issue**: What is &#34;optimal&#34;? Maximum power? Minimum FDR? Best prediction? Different goals ‚Üí different optima.

---

## Evidence the Problem IS Serious

### 1. Real-World Impact on Research

**Arbitrary standards feel unscientific** (and they are):
- Bacterial microbiome: &#34;3% prevalence, 1% abundance&#34;
- Virome: Much higher thresholds due to sparsity
- No theoretical justification for these values
- Different labs use different standards ‚Üí irreproducibility

**Loss of discriminative signal**:
- Example: Feature with 1 read per sample but ALWAYS present in diseased group
- Perfect prevalence association (100% in diseased, 0% in healthy)
- Removed by standard abundance filtering
- Exactly what MaAsLin3 was designed to detect (77% of IBD associations were prevalence)

### 2. Denominator Problem

**Global filtering removes group-specific taxa**:

Example: Comparing Africa vs US microbiomes
- Taxon present in 80% of African samples (highly prevalent locally)
- Taxon present in 2% of US samples (absent in US)
- **Global prevalence**: (0.8 √ó n_Africa + 0.02 √ó n_US) / (n_Africa + n_US)
- If n_US &gt;&gt; n_Africa, global prevalence may be &lt;10% ‚Üí filtered out
- Lost a regionally important taxon!

This is the exact problem the user identified and it&#39;s legitimate.

### 3. P-Hacking Vulnerability

**Researcher degrees of freedom**:
```
1. Try prevalence = 5%, abundance = 1% ‚Üí p = 0.07
2. Try prevalence = 8%, abundance = 0.5% ‚Üí p = 0.04
3. Publish with &#34;standard 8% prevalence filter&#34;
```

This is not hypothetical - it happens. Filtering decisions post-hoc based on results is problematic.

### 4. Field Recognition of Problem

**Recent methods specifically address this**:
- MaAsLin3 (2024): Models prevalence vs abundance separately
- ANCOM-BC2 (2024): Sensitivity analysis for pseudo-counts
- PERFect (2019): Data-driven thresholds
- MI-based (2022): Threshold-free filtering

If it weren&#39;t a real problem, why would multiple independent groups develop solutions?

---

## Evidence the Problem is LESS Serious Than It Seems

### 1. Modern Methods Handle Sparsity Well

**Regularization was designed for this**:
- LASSO, elastic net, horseshoe priors explicitly handle high-dimensional sparse data
- They automatically shrink noise features to zero
- Filtering is redundant - regularization does the job

**Adaptive FDR methods**:
- IHW increases power 25-68% without pre-filtering
- Uses covariates to weight tests efficiently
- Handles thousands of hypotheses

**Empirical Bayes**:
- limma, DESeq2 borrow information across features
- Naturally down-weight noisy features
- Better than hard filtering

### 2. Historical Artifact

**Pre-filtering may be solving yesterday&#39;s problem**:
- Bonferroni correction: Power ‚àù 1/n_tests ‚Üí fewer tests helps
- Modern FDR: Adaptive to proportion of nulls ‚Üí doesn&#39;t require pre-filtering
- Computational limits: Less relevant with modern hardware

**2024 benchmark**: Classic methods (Wilcoxon, t-test, linear models) control FDR properly without requiring aggressive filtering.

### 3. Results Generally Robust

**Practical observation**:
- Studies using different thresholds generally find similar biological conclusions
- Main findings replicate across labs despite different filtering
- Suggests filtering is not catastrophically wrong, just suboptimal

### 4. Real Problem is Method Choice, Not Filtering

**[2024 benchmark](https://pmc.ncbi.nlm.nih.gov/articles/PMC11423519/)** showed:
- Method choice matters MORE than filtering choice
- MaAsLin2 has FDR issues regardless of filtering
- Classic methods control FDR better with minimal filtering
- Focus on choosing right method, not optimizing filtering

---

## Systematic Analysis: When IS Filtering Actually Needed?

### Always Appropriate: Quality Control Filtering

**Different from statistical filtering**:
1. Remove contaminants (decontam, SourceTracker)
2. Remove sequencing artifacts (chimeras, index switching)
3. Remove unreliable estimates (present in &lt;2 samples)
4. Batch effect correction

This is **data quality**, not statistical filtering. Always do this.

### Context-Dependent: Statistical Filtering

**Legitimate reasons**:

**1. Computational efficiency**
- Large datasets (10,000+ features)
- Complex models slow with many features
- BUT: Modern computers handle this better

**2. Unstable effect estimates**
- Features in 1-2 samples have undefined log-ratios
- High variance that doesn&#39;t shrink well
- Legitimate statistical concern

**3. Interpretability**
- 1,000 significant features is uninterpretable
- Want to focus on most important signals
- BUT: This is presentation, not statistics

**4. Method-specific requirements**
- ALDEx2: CLR breaks with extreme zeros, recommends &gt;10% prevalence
- ANCOM-BC: Slow with many features
- Specific technical limitations

**Questionable reasons**:

**1. &#34;Reducing FDR penalty&#34;**
- Adaptive FDR methods handle this
- Empirical null proportion estimation
- May not need pre-filtering

**2. &#34;Removing noise&#34;**
- Regularization does this automatically
- Risk of removing signal

---

## The Bayesian Optimization Question

### Arguments FOR Bayesian Threshold Estimation

**Intellectually elegant**:
- Principled uncertainty quantification
- Natural incorporation of prior knowledge
- Joint estimation of thresholds + model parameters
- Philosophically satisfying

**Analogous to successful approaches**:
- MrBayes/BEAST revolutionized phylogenetics
- Bayesian variable selection works for feature selection
- Why not thresholds?

### Arguments AGAINST (Why It&#39;s Probably Overkill)

**Computational expense**:
- Must refit downstream model at each MCMC iteration
- With thousands of features and complex models: prohibitive
- Unlikely to be adopted if too slow

**Giving false precision**:
- Posterior credible intervals on &#34;optimal&#34; threshold suggest more certainty than warranted
- Optimal for WHAT? (power, FDR, prediction, interpretability?)
- Risk of overfitting to dataset-specific noise

**Simpler alternatives exist**:
- Use methods that don&#39;t require filtering (MaAsLin3, regularization)
- Data-driven thresholds (PERFect, MI-based)
- Sensitivity analysis across fixed thresholds
- Achieve same goal more simply

**Phylogenetic analogy breaks down**:
- Phylogenetics: Single optimization (tree likelihood)
- Filtering: Nested optimization (threshold ‚Üí model fit ‚Üí outcome)
- Different computational complexity

**Modern methods already solve this differently**:
- Spike-and-slab: Probabilistic feature selection (binary)
- MaAsLin3: Model prevalence as outcome (no filtering)
- Regularization: Continuous shrinkage (no thresholding)

**Verdict**: Bayesian optimization is intellectually interesting but practically unnecessary for 95% of use cases.

---

## The Better Solution: Guided Filtering with Diagnostics

### What Researchers Actually Need

Not complex optimization, but **practical guidance**:

**1. Characterize my data**
- How sparse is it?
- What&#39;s the prevalence distribution?
- Are there outlier samples?
- Contamination detected?

**2. Understand filtering impact**
- How many features removed at each threshold?
- What are characteristics of removed vs retained?
- How much information loss (covariance, diversity)?
- Visual comparison

**3. Choose appropriate method**
- Decision tree based on data characteristics
- Clear guidance on when to use what
- Understand trade-offs

**4. Assess robustness**
- Automated sensitivity analysis
- Test multiple thresholds
- Report concordance across approaches
- Identify stable vs unstable findings

### Why Diagnostics &gt; Optimization

**Diagnostics provide**:
- Transparency
- Understanding
- Informed decision-making
- Robustness assessment

**Optimization provides**:
- A single &#34;optimal&#34; answer
- False sense of precision
- Computational complexity
- May overfit

**Analogy**: Exploratory data analysis is often more valuable than complex modeling.

---

## Alternative Paradigms Not Requiring Filtering

### 1. Model Prevalence as Outcome (MaAsLin3)

**Philosophy**: Don&#39;t filter based on prevalence - TEST prevalence!

**Advantage**: Your &#34;1-read but always diseased&#34; example gets detected
**Limitation**: MaAsLin3 has FDR issues in many scenarios

### 2. Regularization (LASSO, Elastic Net, Horseshoe)

**Philosophy**: Let the model do the feature selection

**Advantage**: Automatic, data-driven, continuous (not binary)
**Limitation**: Requires appropriate model setup, cross-validation

### 3. Two-Part Models (ZIBR, ZIGMM)

**Philosophy**: Model zeros (prevalence) and non-zeros (abundance) separately

**Advantage**: Explicit handling of zeros, natural for longitudinal data
**Limitation**: More complex to fit and interpret

### 4. Compositional Methods (ALDEx2, ANCOM-BC)

**Philosophy**: Handle compositionality explicitly, less sensitive to sparsity

**Advantage**: Proper accounting for compositional bias
**Limitation**: Computational cost, specific assumptions

### 5. Information-Theoretic (MI-Based)

**Philosophy**: Filter based on information content, not arbitrary thresholds

**Advantage**: Threshold-free, detects low-abundance true signal
**Limitation**: Relatively new, less widely adopted

---

## The Consensus View

### Problem Assessment

**REAL aspects**:
- Arbitrary thresholds lack justification ‚úì
- Can lose biologically important signal ‚úì
- Context-dependent optimal filtering ‚úì
- P-hacking vulnerability ‚úì
- Reproducibility issues ‚úì

**LESS SERIOUS aspects**:
- Modern methods increasingly handle sparsity ‚úì
- Results generally robust to reasonable choices ‚úì
- Computational barriers less relevant now ‚úì
- Quality control (vs statistical filtering) distinction ‚úì

### Severity Rating: **MODERATE**

**More about research quality and reproducibility than catastrophic errors.**

Not a crisis, but a pervasive quality issue that:
- Reduces statistical power
- Decreases reproducibility
- Creates researcher degrees of freedom
- Perpetuates &#34;soft science&#34; feeling

---

## Research Gaps and Opportunities

### High Value (Practical Impact)

**1. Unified diagnostic package**
```r
library(smartfilter)
diagnostics &lt;- diagnose_filtering(data, thresholds, covariates)
plot(diagnostics)
recommendations &lt;- suggest_strategy(diagnostics)
sensitivity &lt;- test_robustness(diagnostics)
```

**Why valuable**:
- Immediate practical use
- Improves research quality
- No new statistical theory needed
- Fills real gap in workflow

**2. Method selection guidance**
- Decision trees based on data characteristics
- Clear &#34;when to use what&#34;
- Benchmark-informed recommendations
- Interactive tool

**3. Reproducibility standards**
- Pre-registration of filtering strategy
- Mandatory sensitivity reporting
- Standardized reporting guidelines
- Community consensus building

### Medium Value (Methodological)

**1. Covariate-aware filtering**
- Group-specific thresholds
- Hierarchical filtering strategies
- Test on real datasets

**2. Information-theoretic framework**
- Extend MI-based approaches
- MDL for model selection
- Information gain metrics

### Lower Value (Academic Interest)

**1. Bayesian threshold optimization**
- Intellectually interesting
- Computationally expensive
- Practically overkill for most cases
- Academic contribution, limited adoption

**2. New differential abundance methods**
- Field already has too many methods
- Disagreement more confusing than helpful
- Focus on benchmarking existing methods

---

## Recommendations for Practice

### Immediate Actions

**1. Use methods that don&#39;t require filtering**
- MaAsLin3 for prevalence associations (despite FDR caveats)
- LinDA, ANCOM-BC2 for dense signals
- Regularization methods for high-dimensional data

**2. When filtering needed, use principled approaches**
- MI-based for threshold-free
- PERFect for data-driven thresholds
- Treat as hyperparameter in ML pipelines

**3. Always run sensitivity analysis**
- Test multiple threshold combinations
- Report robustness of findings
- Identify stable results

**4. Pre-specify filtering strategy**
- Document before analyzing
- Avoid post-hoc tuning
- Prevents p-hacking

### Long-Term Solutions

**1. Tool development**
- Diagnostic packages (highest priority)
- Automated sensitivity testing
- Interactive visualizations

**2. Community standards**
- Reporting guidelines
- Pre-registration expectations
- Benchmark updates

**3. Education**
- When filtering is/isn&#39;t needed
- Method selection guidance
- Best practices training

---

## Final Verdict

### Is Bayesian Optimization Necessary?

**NO** - It&#39;s solving the problem at the wrong level.

The field is solving filtering by:
1. Using methods that don&#39;t require it
2. Making filtering decisions more transparent
3. Requiring sensitivity analysis

NOT by finding &#34;optimal&#34; thresholds.

### Is the Problem Serious?

**YES, BUT TRANSITIONING**

- Real impact on research quality
- Being addressed through better methods
- Needs practical tools, not complex theory
- Diagnostic-guided approach is right level

### What&#39;s Actually Needed?

**Practical tools &gt; Statistical theory**

Researchers need:
- Data characterization tools
- Method selection guidance
- Sensitivity analysis automation
- Reporting standards

NOT:
- Bayesian optimization
- New DA methods
- Complex theoretical frameworks

### The Pragmatic Path Forward

**Build the diagnostic package.**

It will have immediate impact, improve research quality, and doesn&#39;t require solving hard theoretical problems. Everything else is intellectual masturbation.

---

## Key Insights

1. **The phylogenetic analogy is interesting but misleading** - different computational structure
2. **Modern methods are solving this differently** - model prevalence, regularize, adapt FDR
3. **Filtering is transitioning from critical to legacy** - necessary for older methods, optional for newer
4. **Quality control ‚â† statistical filtering** - always do QC, be thoughtful about statistical
5. **Method choice matters more than filtering** - focus energy there
6. **Diagnostics &gt; optimization** - transparency and robustness beat &#34;optimality&#34;
7. **The field needs tools, not theory** - practical impact from software, not papers

---

## Conclusion

Prevalence filtering optimization is a **real but overstated problem** that is better addressed through:

1. **Adopting methods that don&#39;t require filtering**
2. **Using data-driven approaches when filtering is needed**
3. **Running sensitivity analyses** to assess robustness
4. **Building diagnostic tools** to guide researchers
5. **Establishing reporting standards** for transparency

The Bayesian optimization approach, while intellectually elegant, is **practically unnecessary** for the vast majority of use cases. The field needs better **tools and workflows**, not more sophisticated **statistical theory**.

The pragmatic solution is a **diagnostic and guidance package** that helps researchers make informed, transparent decisions - not an algorithm that claims to find &#34;optimal&#34; thresholds.

**Bottom line**: This is a tooling and workflow problem masquerading as a statistical theory problem.
</pre></div><button class="expand-btn">Show more</button></div>
</div></div></div>
<div class="message tool-reply" id="msg-2025-12-13T02-17-04-883Z"><div class="message-header"><span class="role-label">Tool reply</span><a href="#msg-2025-12-13T02-17-04-883Z" class="timestamp-link"><time datetime="2025-12-13T02:17:04.883Z" data-timestamp="2025-12-13T02:17:04.883Z">2025-12-13T02:17:04.883Z</time></a></div><div class="message-content"><div class="tool-result"><div class="truncatable"><div class="truncatable-content"><pre>File created successfully at: /Users/scotthandley/Code/smart_prev_filter/critical_analysis.md</pre></div><button class="expand-btn">Show more</button></div></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-17-08-900Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-17-08-900Z" class="timestamp-link"><time datetime="2025-12-13T02:17:08.900Z" data-timestamp="2025-12-13T02:17:08.900Z">2025-12-13T02:17:08.900Z</time></a></div><div class="message-content">
<div class="thinking"><div class="thinking-label">Thinking</div><p>Now let me create the practical recommendations document with decision trees and implementation guidance.</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-19-14-648Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-19-14-648Z" class="timestamp-link"><time datetime="2025-12-13T02:19:14.648Z" data-timestamp="2025-12-13T02:19:14.648Z">2025-12-13T02:19:14.648Z</time></a></div><div class="message-content"><div class="file-tool write-tool" data-tool-id="toolu_01Ejj1HHQuER6tSTKMFhiPZW">
<div class="file-tool-header write-header"><span class="file-tool-icon">üìù</span> Write <span class="file-tool-path">practical_recommendations.md</span></div>
<div class="file-tool-fullpath">/Users/scotthandley/Code/smart_prev_filter/practical_recommendations.md</div>
<div class="truncatable"><div class="truncatable-content"><pre class="file-content"># Practical Recommendations: Method Selection and Filtering Strategy

## Quick Start: Decision Trees

### Primary Decision Tree: Method Selection

```
START: What type of comparison are you doing?

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Q1: Is this a simple case vs control comparison?    ‚îÇ
‚îÇ     (No covariates, no repeated measures)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ YES ‚îÄ‚îÄ‚Üí Use: Wilcoxon rank-sum test
         ‚îÇ          Alt: limma, fastANCOM
         ‚îÇ          Avoid: MaAsLin2, DESeq2
         ‚îÇ
         ‚îî‚îÄ NO ‚îÄ‚îÄ‚îÄ‚Üí Continue to Q2

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Q2: Do you expect many features to differ?          ‚îÇ
‚îÇ     (Dense signal: dysbiosis, major perturbation)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ YES ‚îÄ‚îÄ‚Üí Use: LinDA or ANCOM-BC2
         ‚îÇ          Avoid: MaAsLin2 (FDR inflation)
         ‚îÇ
         ‚îî‚îÄ NO ‚îÄ‚îÄ‚îÄ‚Üí Continue to Q3

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Q3: Is compositional bias a major concern?          ‚îÇ
‚îÇ     (Dominant taxa, bloom events)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ YES ‚îÄ‚îÄ‚Üí Use: ALDEx2 or ANCOM-BC
         ‚îÇ          (Explicit bias correction)
         ‚îÇ
         ‚îî‚îÄ NO ‚îÄ‚îÄ‚îÄ‚Üí Continue to Q4

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Q4: Do you need to distinguish prevalence vs        ‚îÇ
‚îÇ     abundance associations?                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ YES ‚îÄ‚îÄ‚Üí Use: MaAsLin3 or two-part models
         ‚îÇ          Note: MaAsLin3 has FDR caveats
         ‚îÇ
         ‚îî‚îÄ NO ‚îÄ‚îÄ‚îÄ‚Üí Continue to Q5

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Q5: Is computational speed critical?                ‚îÇ
‚îÇ     (Large dataset, many features)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ YES ‚îÄ‚îÄ‚Üí Use: LinDA
         ‚îÇ          (100-1000√ó faster than ANCOM-BC)
         ‚îÇ
         ‚îî‚îÄ NO ‚îÄ‚îÄ‚îÄ‚Üí Use: ANCOM-BC2 (most balanced)
                    or MaAsLin3 (if need flexibility)
```

### Filtering Decision Tree

```
START: Do you need to filter?

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Are you using a method that doesn&#39;t require         ‚îÇ
‚îÇ filtering? (MaAsLin3, regularization, adaptive FDR) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ YES ‚îÄ‚îÄ‚Üí Skip statistical filtering
         ‚îÇ          (Still do quality control!)
         ‚îÇ
         ‚îî‚îÄ NO ‚îÄ‚îÄ‚îÄ‚Üí Continue

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Quality Control Filtering (ALWAYS DO THIS)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚îú‚îÄ‚Üí Remove contaminants (decontam, SourceTracker)
    ‚îú‚îÄ‚Üí Remove chimeras (if 16S)
    ‚îú‚îÄ‚Üí Remove features present in &lt;2 samples
    ‚îî‚îÄ‚Üí Check for batch effects

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Statistical Filtering (METHOD DEPENDENT)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚îú‚îÄ ALDEx2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Filter &lt;10% prevalence (CLR requires it)
    ‚îú‚îÄ ANCOM-BC ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Minimal (slow with many features)
    ‚îú‚îÄ LinDA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí 10-20% prevalence recommended
    ‚îú‚îÄ Wilcoxon ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí 5-10% prevalence
    ‚îî‚îÄ Classical ‚îÄ‚îÄ‚îÄ‚Üí 10% prevalence standard

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ How to choose threshold?                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚îú‚îÄ Data-driven ‚îÄ‚îÄ‚Üí Use PERFect or MI-based
    ‚îú‚îÄ Pre-specified ‚îÄ‚Üí Community standard for your field
    ‚îî‚îÄ Sensitivity ‚îÄ‚îÄ‚îÄ‚Üí Test multiple, report robustness
```

---

## Method-Specific Guidance

### Wilcoxon Rank-Sum Test (Simple Comparisons)

**When to use**:
- ‚úÖ Simple case vs control
- ‚úÖ No covariates to adjust
- ‚úÖ Want robust non-parametric test
- ‚úÖ 2024 benchmark: best FDR control

**When NOT to use**:
- ‚ùå Need covariate adjustment
- ‚ùå Multiple groups (&gt;2)
- ‚ùå Repeated measures/longitudinal

**Filtering**:
```r
# Prevalence: 5-10%
# Abundance: minimal (Wilcoxon handles zeros)

phyloseq_filtered &lt;- filter_taxa(
  physeq,
  function(x) sum(x &gt; 0) &gt; (0.10 * length(x)),
  TRUE
)
```

**FDR correction**:
```r
# Use BH or IHW for better power
p_adjusted &lt;- p.adjust(pvalues, method = &#34;BH&#34;)
# or
library(IHW)
results &lt;- ihw(pvalues, covariates = mean_abundance, alpha = 0.05)
```

### limma-voom

**When to use**:
- ‚úÖ Simple or complex designs
- ‚úÖ Proven FDR control
- ‚úÖ Familiar to RNA-seq users
- ‚úÖ Fast and flexible

**Setup**:
```r
library(limma)
library(edgeR)

# TMM normalization
dge &lt;- DGEList(counts = otu_table)
dge &lt;- calcNormFactors(dge, method = &#34;TMM&#34;)

# Design matrix
design &lt;- model.matrix(~ group + covariate)

# voom transformation
v &lt;- voom(dge, design, plot = TRUE)

# Fit model
fit &lt;- lmFit(v, design)
fit &lt;- eBayes(fit)

# Results
results &lt;- topTable(fit, coef = 2, number = Inf)
```

**Filtering**: 5-10% prevalence, minimal abundance

### ALDEx2 (Conservative, Compositional-Aware)

**When to use**:
- ‚úÖ Small sample sizes (n &lt; 20)
- ‚úÖ Strong compositional bias concerns
- ‚úÖ Want conservative FDR control
- ‚úÖ Can tolerate low power

**When NOT to use**:
- ‚ùå Need maximum sensitivity
- ‚ùå Rare taxa are focus
- ‚ùå Very large datasets (slow)

**Implementation**:
```r
library(ALDEx2)

# Requires groups as factors
conditions &lt;- factor(metadata$group)

# ALDEx2 analysis
x &lt;- aldex.clr(otu_table, conditions, mc.samples = 128)
x.tt &lt;- aldex.ttest(x, conditions)
x.effect &lt;- aldex.effect(x, conditions)

# Combine results
results &lt;- data.frame(x.tt, x.effect)

# Significance: BH corrected p &lt; 0.05 AND effect size &gt; 1
sig &lt;- results$we.eBH &lt; 0.05 &amp; abs(results$effect) &gt; 1
```

**Filtering**:
- **Required**: &gt;10% prevalence (CLR transformation breaks with too many zeros)
- Use `aldex.filter` for data-driven filtering

### ANCOM-BC2 (Balanced, Handles Complex Designs)

**When to use**:
- ‚úÖ Complex designs (multigroup, covariates, repeated measures)
- ‚úÖ Need bias correction
- ‚úÖ Can tolerate computational cost
- ‚úÖ Want sensitivity analysis

**When NOT to use**:
- ‚ùå Very large datasets (very slow)
- ‚ùå Very small sample sizes (&lt;10 per group)
- ‚ùå Simple case vs control (overkill)

**Implementation**:
```r
library(ANCOMBC)

# Complex design with covariates and random effects
output &lt;- ancombc2(
  data = phyloseq_obj,
  fix_formula = &#34;disease + treatment + country&#34;,
  rand_formula = &#34;(1|PatientID)&#34;,
  p_adj_method = &#34;holm&#34;,
  prv_cut = 0.10,          # Prevalence filter
  lib_cut = 1000,          # Library size cutoff
  group = &#34;disease&#34;,
  struc_zero = TRUE,       # Detect structural zeros
  neg_lb = TRUE,           # Bias correction
  pseudo_sens = TRUE,      # Sensitivity analysis
  pseudo_sens_cut = c(0.1, 0.5, 1.0)
)

# Results
res &lt;- output$res
# Check sensitivity: output$pseudo_sens_tab
```

**Filtering**: Minimal (10% prevalence), relies on bias correction

### LinDA (Fast, Balanced)

**When to use**:
- ‚úÖ Large datasets requiring speed
- ‚úÖ Multigroup comparisons
- ‚úÖ Need covariate adjustment
- ‚úÖ 100-1000√ó faster than ANCOM-BC

**When NOT to use**:
- ‚ùå Dense continuous covariates (FDR inflation)
- ‚ùå Need explicit bias estimation like ANCOM-BC

**Implementation**:
```r
library(MicrobiomeStat)

# Prepare data
linda_obj &lt;- linda(
  feature.dat = otu_table,  # OTU table
  meta.dat = metadata,      # Sample metadata
  formula = &#39;~ disease + treatment + country&#39;,
  alpha = 0.05,
  prev.filter = 0.10,       # Prevalence filter
  mean.abund.filter = 0,    # Mean abundance filter
  adaptive = TRUE,          # Adaptive FDR
  max.abund.filter = 0,
  corr.cut = 0.1
)

# Results
res &lt;- linda_obj$output
```

**Filtering**: 10-20% prevalence recommended

### MaAsLin3 (Prevalence vs Abundance)

**When to use**:
- ‚úÖ Need to distinguish prevalence vs abundance associations
- ‚úÖ Complex covariate structures
- ‚úÖ Random effects needed
- ‚úÖ Sparse data with important rare features

**When NOT to use**:
- ‚ùå Dense signals (FDR inflation)
- ‚ùå Strong compositional effects (poor FDR control)
- ‚ùå Simple comparisons (too complex)
- ‚ùå Need maximum FDR control

**Implementation**:
```r
library(maaslin3)

fit_data &lt;- maaslin3(
  input_data = otu_table,
  input_metadata = metadata,
  output = &#34;output_folder&#34;,
  formula = &#34;~ disease + treatment + country + sequencing_depth + (1|PatientID)&#34;,
  random_effects = c(&#34;PatientID&#34;),
  normalization = &#34;TSS&#34;,
  transform = &#34;LOG&#34;,
  test_prevalence = TRUE,        # Key feature!
  standardize = FALSE,
  min_prevalence = 0.10,         # Can be lower if testing prevalence
  min_abundance = 0,
  max_significance = 0.05
)

# Separate prevalence and abundance results
prev_results &lt;- fit_data$results[fit_data$results$test_type == &#34;prevalence&#34;, ]
abund_results &lt;- fit_data$results[fit_data$results$test_type == &#34;abundance&#34;, ]
```

**Critical**: Include sequencing depth as covariate when testing prevalence!

**Filtering**: Can use lower thresholds since prevalence is tested

---

## Filtering Strategies

### Strategy 1: Data-Driven (PERFect)

**Best for**: Objective threshold determination

```r
library(PERFect)

# Permutation filtering
res_pf &lt;- PERFect_perm(
  X = otu_table,          # Rows = samples, columns = OTUs
  Order = &#34;pvals&#34;,        # Order by p-values
  pvals_sim = pvals,      # P-values from permutation test
  alpha = 0.05,
  rollmean = TRUE
)

# Simultaneous filtering
res_sim &lt;- PERFect_sim(
  X = otu_table,
  alpha = 0.05
)

# Visualize filtering loss
plot(res_pf)

# Get filtered data
filtered_data &lt;- res_pf$filtX
```

### Strategy 2: Threshold-Free (MI-Based)

**Best for**: Preserving low-abundance discriminative features

```r
# MI-based filtering requires network construction
# See: https://github.com/FrederickHuangLin/ANCOMBC

# Basic approach:
# 1. Calculate mutual information between all taxa pairs
# 2. Build network based on MI values
# 3. Identify contaminants vs true taxa using graph properties
# 4. Filter out contaminants

# Implementation requires specialized package
```

### Strategy 3: Sensitivity Analysis

**Best for**: Assessing robustness, preventing p-hacking

```r
# Define threshold grid
thresholds &lt;- expand.grid(
  prevalence = c(0, 0.05, 0.10, 0.20, 0.30),
  abundance = c(0, 0.001, 0.01, 0.1)
)

# Function to run analysis with specific threshold
run_with_threshold &lt;- function(prev_thresh, abund_thresh) {
  # Filter data
  filtered &lt;- filter_taxa(
    physeq,
    function(x) {
      prevalence &lt;- sum(x &gt; 0) / length(x)
      mean_abund &lt;- mean(x[x &gt; 0])
      prevalence &gt;= prev_thresh &amp; mean_abund &gt;= abund_thresh
    },
    TRUE
  )

  # Run your analysis
  results &lt;- your_analysis_function(filtered)

  return(results)
}

# Run across all thresholds
all_results &lt;- mapply(
  run_with_threshold,
  thresholds$prevalence,
  thresholds$abundance,
  SIMPLIFY = FALSE
)

# Identify features significant across multiple thresholds
robust_features &lt;- find_concordant_features(all_results)

# Report
cat(sprintf(
  &#34;Found %d features significant in &gt;80%% of threshold combinations&#34;,
  length(robust_features)
))
```

### Strategy 4: Hyperparameter Tuning (ML Pipelines)

**Best for**: Predictive modeling

```r
library(caret)

# Define preprocessing function
preprocess_with_filter &lt;- function(data, prev_thresh, abund_thresh) {
  filtered &lt;- filter_taxa(data, ...)
  return(filtered)
}

# Set up cross-validation
train_control &lt;- trainControl(
  method = &#34;cv&#34;,
  number = 10,
  search = &#34;grid&#34;
)

# Define tuning grid including filtering thresholds
tune_grid &lt;- expand.grid(
  prevalence = c(0.05, 0.10, 0.20),
  abundance = c(0.01, 0.1),
  # ... other model hyperparameters
)

# Train model with filtering as hyperparameter
model &lt;- train(
  outcome ~ .,
  data = data,
  method = &#34;rf&#34;,
  trControl = train_control,
  tuneGrid = tune_grid,
  preProcess = function(x) preprocess_with_filter(x, ...)
)

# Best filtering threshold from CV
best_filter &lt;- model$bestTune
```

---

## Practical Workflows

### Workflow 1: Simple Case vs Control

```r
# 1. Quality control
physeq_clean &lt;- remove_contaminants(physeq)
physeq_clean &lt;- remove_low_counts(physeq_clean, min_samples = 2)

# 2. Minimal filtering
physeq_filt &lt;- filter_taxa(
  physeq_clean,
  function(x) sum(x &gt; 0) &gt; (0.05 * length(x)),
  TRUE
)

# 3. Wilcoxon test
library(phyloseq)
library(microbiome)

results &lt;- apply(otu_table(physeq_filt), 1, function(x) {
  group1 &lt;- x[metadata$group == &#34;case&#34;]
  group2 &lt;- x[metadata$group == &#34;control&#34;]
  wilcox.test(group1, group2)$p.value
})

# 4. FDR correction with IHW (better power)
library(IHW)
mean_abund &lt;- rowMeans(otu_table(physeq_filt))
ihw_res &lt;- ihw(results, covariates = mean_abund, alpha = 0.05)

# 5. Report
sig_taxa &lt;- which(adj_pvalues(ihw_res) &lt; 0.05)
```

### Workflow 2: Complex Design with Covariates

```r
# 1. Quality control
physeq_clean &lt;- remove_contaminants(physeq)

# 2. Choose method based on data characteristics
n_samples &lt;- nsamples(physeq_clean)
sparsity &lt;- sum(otu_table(physeq_clean) == 0) / prod(dim(otu_table(physeq_clean)))

if (sparsity &gt; 0.9 &amp; n_samples &lt; 50) {
  # Very sparse, small n: Use ALDEx2
  method &lt;- &#34;ALDEx2&#34;
} else if (n_samples &gt; 200) {
  # Large dataset: Use LinDA for speed
  method &lt;- &#34;LinDA&#34;
} else {
  # Balanced: Use ANCOM-BC2
  method &lt;- &#34;ANCOM-BC2&#34;
}

# 3. Run analysis with sensitivity analysis
run_sensitivity_analysis(physeq_clean, method, ...)

# 4. Report concordance
```

### Workflow 3: Prevalence vs Abundance Focus

```r
# 1. Use MaAsLin3 or two-part model
# 2. Include sequencing depth as covariate
# 3. Compare prevalence vs abundance associations
# 4. Validate with separate presence/absence and abundance tests

# MaAsLin3 approach
maaslin3_res &lt;- maaslin3(
  input_data = otu_table,
  input_metadata = metadata,
  formula = &#34;~ disease + sequencing_depth&#34;,
  test_prevalence = TRUE,
  min_prevalence = 0.05  # Can be lower
)

# Separate two-part approach
# Part 1: Presence/absence (logistic regression)
presence &lt;- (otu_table &gt; 0) * 1
prev_results &lt;- apply(presence, 1, function(x) {
  fit &lt;- glm(x ~ disease, data = metadata, family = &#34;binomial&#34;)
  summary(fit)$coefficients[2, 4]  # p-value
})

# Part 2: Abundance given presence (on non-zero samples)
abund_results &lt;- apply(otu_table, 1, function(x) {
  present &lt;- x &gt; 0
  if(sum(present) &gt; 10) {
    fit &lt;- lm(log(x[present]) ~ disease[present], data = metadata[present, ])
    summary(fit)$coefficients[2, 4]
  } else {
    NA
  }
})

# Compare: Which associations are prevalence vs abundance?
```

---

## Diagnostic Checklist

### Pre-Analysis Diagnostics

**Run these BEFORE filtering decisions**:

```r
# 1. Sample depth distribution
hist(sample_sums(physeq), main = &#34;Sequencing Depth Distribution&#34;)

# 2. Rarefaction curves
rarecurve(otu_table(physeq), step = 100)

# 3. Sparsity assessment
sparsity &lt;- sum(otu_table(physeq) == 0) / prod(dim(otu_table(physeq)))
cat(sprintf(&#34;Sparsity: %.1f%%\n&#34;, sparsity * 100))

# 4. Prevalence distribution
prevalence_dist &lt;- apply(otu_table(physeq), 1, function(x) sum(x &gt; 0) / length(x))
hist(prevalence_dist, main = &#34;Prevalence Distribution&#34;, breaks = 50)

# 5. Abundance distribution
mean_abundance &lt;- rowMeans(otu_table(physeq))
hist(log10(mean_abundance[mean_abundance &gt; 0]), main = &#34;Log10 Mean Abundance&#34;)

# 6. Contamination check
library(decontam)
contam &lt;- isContaminant(physeq, method = &#34;frequency&#34;, conc = metadata$DNA_conc)
table(contam$contaminant)

# 7. Batch effect check
ord &lt;- ordinate(physeq, method = &#34;PCoA&#34;, distance = &#34;bray&#34;)
plot_ordination(physeq, ord, color = &#34;batch&#34;)
```

### Post-Filtering Diagnostics

**Run these AFTER filtering to assess impact**:

```r
# 1. How many features removed?
n_before &lt;- ntaxa(physeq_before)
n_after &lt;- ntaxa(physeq_after)
cat(sprintf(&#34;Removed %d features (%.1f%%)\n&#34;,
    n_before - n_after,
    (n_before - n_after) / n_before * 100))

# 2. Characteristics of removed vs retained
removed_taxa &lt;- setdiff(taxa_names(physeq_before), taxa_names(physeq_after))
removed_prev &lt;- prevalence_dist[removed_taxa]
retained_prev &lt;- prevalence_dist[taxa_names(physeq_after)]

boxplot(list(Removed = removed_prev, Retained = retained_prev),
        main = &#34;Prevalence: Removed vs Retained&#34;)

# 3. Beta diversity before vs after
dist_before &lt;- distance(physeq_before, &#34;bray&#34;)
dist_after &lt;- distance(physeq_after, &#34;bray&#34;)
cor(as.vector(dist_before), as.vector(dist_after))

# 4. Alpha diversity impact
alpha_before &lt;- estimate_richness(physeq_before, measures = &#34;Shannon&#34;)
alpha_after &lt;- estimate_richness(physeq_after, measures = &#34;Shannon&#34;)
plot(alpha_before$Shannon, alpha_after$Shannon,
     xlab = &#34;Before&#34;, ylab = &#34;After&#34;, main = &#34;Shannon Diversity&#34;)
abline(0, 1, col = &#34;red&#34;)
```

---

## Reporting Standards

### What to Report in Methods

**Minimum requirements**:

1. **Quality control filtering**:
   - Contaminant removal method (if applicable)
   - Minimum sample prevalence threshold
   - Sample filtering criteria

2. **Statistical filtering**:
   - Prevalence threshold (e.g., &#34;features present in &lt;10% of samples were excluded&#34;)
   - Abundance threshold (if applicable)
   - Rationale for threshold choice

3. **Method selection**:
   - Differential abundance method used
   - Why this method was chosen (cite benchmarks)
   - Parameters/settings

4. **Multiple testing correction**:
   - FDR method (BH, IHW, etc.)
   - Significance threshold

**Best practices (should report)**:

5. **Sensitivity analysis**:
   - &#34;Results were robust across prevalence thresholds of 5-20%&#34;
   - Report concordance metrics

6. **Data characteristics**:
   - Sample size per group
   - Sparsity level
   - Sequencing depth distribution

7. **Software versions**:
   - R version
   - Package versions (sessionInfo())

### Example Methods Statement

```
Taxonomic features were filtered using a two-step approach. First,
quality control filtering removed likely contaminants identified
by the decontam package (v1.12.0) using the frequency method, and
features present in fewer than 2 samples. Second, statistical
filtering removed features present in &lt;10% of samples to reduce
multiple testing burden and improve estimate stability.

Differential abundance testing was performed using LinDA (v1.0.0)
which adjusts for compositional effects. We chose LinDA based on
recent benchmarks showing it maintains proper FDR control while
offering 100-fold speed improvements over ANCOM-BC. The model
included disease status, treatment, and country as fixed effects:
~ disease + treatment + country. FDR correction was performed
using the Benjamini-Hochberg procedure with Œ± = 0.05.

Sensitivity analyses confirmed that results were robust to
prevalence thresholds ranging from 5-20%, with 87% of significant
features identified consistently across all thresholds tested.
```

---

## Common Pitfalls to Avoid

### ‚ùå Don&#39;t:

1. **Tune filtering to get desired p-value**
   - Pre-specify threshold before seeing results
   - Or use data-driven method (PERFect) blind to outcome

2. **Filter differently for different groups**
   - Apply same threshold to all samples
   - Exception: Stratified analysis with pre-specified plan

3. **Use DESeq2/edgeR without understanding limitations**
   - These have severe FDR inflation in microbiome data
   - Use microbiome-specific methods instead

4. **Ignore compositional effects**
   - Microbiome data is compositional
   - Use methods that account for this (ALDEx2, ANCOM-BC, LinDA)

5. **Report only significant results from one threshold**
   - Show sensitivity across thresholds
   - Report which findings are robust

6. **Use MaAsLin for everything**
   - It has limitations (FDR inflation with dense signals)
   - Choose method based on your specific scenario

### ‚úÖ Do:

1. **Always do quality control filtering**
   - Remove contaminants
   - Remove unreliable features (&lt;2 samples)
   - Check for batch effects

2. **Choose method based on data characteristics**
   - Use decision tree above
   - Consult recent benchmarks

3. **Run sensitivity analyses**
   - Test multiple thresholds
   - Test multiple methods
   - Report concordance

4. **Visualize your data**
   - Before filtering
   - After filtering
   - Understand what you&#39;re removing

5. **Pre-register analysis plan**
   - Specify filtering strategy before analysis
   - Document deviations

6. **Report transparently**
   - How many features removed
   - Why this threshold
   - Sensitivity results

---

## Quick Reference: Method Comparison Table

| Method | FDR Control | Power | Speed | Covariates | Random Effects | Best For |
|--------|-------------|-------|-------|------------|----------------|----------|
| **Wilcoxon** | ‚úì‚úì‚úì | ‚úì‚úì | ‚úì‚úì‚úì | ‚úó | ‚úó | Simple comparisons |
| **limma** | ‚úì‚úì‚úì | ‚úì‚úì‚úì | ‚úì‚úì‚úì | ‚úì‚úì‚úì | ‚úì | Flexible designs |
| **ALDEx2** | ‚úì‚úì‚úì | ‚úì | ‚úì | ‚úì | ‚úó | Small n, compositional |
| **ANCOM-BC2** | ‚úì‚úì | ‚úì‚úì‚úì | ‚úì | ‚úì‚úì‚úì | ‚úì‚úì‚úì | Complex designs |
| **LinDA** | ‚úì‚úì | ‚úì‚úì‚úì | ‚úì‚úì‚úì | ‚úì‚úì‚úì | ‚úì | Large datasets |
| **MaAsLin3** | ‚úì | ‚úì‚úì | ‚úì‚úì | ‚úì‚úì‚úì | ‚úì‚úì‚úì | Prevalence testing |
| **DESeq2** | ‚úó | ‚úì‚úì‚úì | ‚úì‚úì | ‚úì‚úì | ‚úó | Avoid for microbiome |
| **fastANCOM** | ‚úì‚úì‚úì | ‚úì‚úì | ‚úì‚úì‚úì | ‚úì | ‚úó | Simple, fast |

Legend: ‚úì‚úì‚úì Excellent | ‚úì‚úì Good | ‚úì Acceptable | ‚úó Poor/Not available

---

## Conclusion

**Key principles**:

1. **Quality control first** - always remove contaminants and unreliable features
2. **Method choice matters** - use decision tree to select appropriate method
3. **Be transparent** - document and report all decisions
4. **Assess robustness** - run sensitivity analyses
5. **Pre-specify** - avoid post-hoc tuning to achieve significance

**When in doubt**:
- Use LinDA or ANCOM-BC2 (best overall performance)
- Filter at 10% prevalence (reasonable default)
- Run sensitivity analysis (assess robustness)
- Report everything (transparency)

**Remember**: No single method is perfect. Understanding your data characteristics and choosing the appropriate method is more important than optimizing filtering thresholds.
</pre></div><button class="expand-btn">Show more</button></div>
</div></div></div>
<div class="message tool-reply" id="msg-2025-12-13T02-19-14-690Z"><div class="message-header"><span class="role-label">Tool reply</span><a href="#msg-2025-12-13T02-19-14-690Z" class="timestamp-link"><time datetime="2025-12-13T02:19:14.690Z" data-timestamp="2025-12-13T02:19:14.690Z">2025-12-13T02:19:14.690Z</time></a></div><div class="message-content"><div class="tool-result"><div class="truncatable"><div class="truncatable-content"><pre>File created successfully at: /Users/scotthandley/Code/smart_prev_filter/practical_recommendations.md</pre></div><button class="expand-btn">Show more</button></div></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-19-19-775Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-19-19-775Z" class="timestamp-link"><time datetime="2025-12-13T02:19:19.775Z" data-timestamp="2025-12-13T02:19:19.775Z">2025-12-13T02:19:19.775Z</time></a></div><div class="message-content">
<div class="thinking"><div class="thinking-label">Thinking</div><p>Finally, let me create a comprehensive references document with all the sources we discussed.</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-21-19-672Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-21-19-672Z" class="timestamp-link"><time datetime="2025-12-13T02:21:19.672Z" data-timestamp="2025-12-13T02:21:19.672Z">2025-12-13T02:21:19.672Z</time></a></div><div class="message-content"><div class="file-tool write-tool" data-tool-id="toolu_01Xrh2pL7U7mx5H39ohW8APj">
<div class="file-tool-header write-header"><span class="file-tool-icon">üìù</span> Write <span class="file-tool-path">references.md</span></div>
<div class="file-tool-fullpath">/Users/scotthandley/Code/smart_prev_filter/references.md</div>
<div class="truncatable"><div class="truncatable-content"><pre class="file-content"># References and Resources

## Comprehensive Bibliography

### Systematic Filtering Methods

**PERFect (PERmutation Filtering test)**
- Smirnova, E., Huzurbazar, S., &amp; Jafari, F. (2019). PERFect: PERmutation Filtering test for microbiome data. *Biostatistics*, 20(4), 615-631.
- Link: https://academic.oup.com/biostatistics/article/20/4/615/5039878
- Key contribution: Data-driven threshold determination via permutation testing and covariance loss minimization

**Mutual Information-Based Filtering**
- Liu, Y., et al. (2022). Filtering ASVs/OTUs via mutual information-based microbiome network analysis. *BMC Bioinformatics*, 23, 381.
- Link: https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-022-04919-0
- Key contribution: Threshold-free filtering that preserves low-abundance true taxa

**Mutual Information Comparative Analysis (2024)**
- Francis, D., &amp; Sun, F. (2024). A comparative analysis of mutual information methods for pairwise relationship detection in metagenomic data. *BMC Bioinformatics*, 25(1), 263.
- Link: https://link.springer.com/article/10.1186/s12859-024-05883-7
- Key contribution: MI uncovers relationships missed by correlation alone

---

### Study-Design Aware Methods

**ANCOM-BC2**
- Lin, H., &amp; Peddada, S. D. (2024). Multigroup analysis of compositions of microbiomes with covariate adjustments and repeated measures. *Nature Methods*, 21, 83-91.
- Link: https://www.nature.com/articles/s41592-023-02092-7
- Bioconductor: https://www.bioconductor.org/packages/release/bioc/html/ANCOMBC.html
- Key contribution: Complex designs with covariates, repeated measures, sensitivity analysis

**MaAsLin3**
- Mallick, H., et al. (2024). MaAsLin 3: Refining and extending generalized multivariable linear models for meta-omic association discovery. *bioRxiv*.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC11661281/
- GitHub: https://github.com/biobakery/maaslin3
- Bioconductor: https://bioconductor.org/packages/devel/bioc/html/maaslin3.html
- Key contribution: Distinguishes prevalence vs abundance associations (77% of IBD associations were prevalence)

**MaAsLin2**
- Mallick, H., et al. (2021). Multivariable association discovery in population-scale meta-omics studies. *PLOS Computational Biology*, 17(11), e1009442.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC8714082/
- GitHub: https://github.com/biobakery/Maaslin2
- Key contribution: Flexible multivariable associations with random effects

**LinDA**
- Zhou, H., et al. (2022). LinDA: linear models for differential abundance analysis of microbiome compositional data. *Genome Biology*, 23, 95.
- Link: https://link.springer.com/article/10.1186/s13059-022-02655-5
- Key contribution: 100-1000√ó faster than ANCOM-BC with competitive performance

**LDM (Linear Decomposition Model)**
- Hu, Y. J., &amp; Satten, G. A. (2020). Testing hypotheses about the microbiome using the linear decomposition model (LDM). *Bioinformatics*, 36(14), 4106-4115.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC8453243/
- CRAN: https://cran.r-project.org/web/packages/LDM/index.html
- GitHub: https://github.com/yijuanhu/LDM
- Key contribution: Distance-based testing with covariate adjustment

**LDM Extension for Presence-Absence**
- Hu, Y. J., et al. (2021). A rarefaction-based extension of the LDM for testing presence-absence associations in the microbiome. *Bioinformatics*, 37(12), 1652-1657.
- Link: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8289387/

---

### Bayesian Variable Selection

**Spike-and-Slab for Zero-Inflated Models**
- Ren, B., et al. (2020). Bayesian variable selection for multivariate zero-inflated models: Application to microbiome count data. *Biostatistics*, 21(3), 499-517.
- Link: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7308073/

**VBayesMM (Neural Network with Spike-and-Slab)**
- Nguyen, H., et al. (2024). VBayesMM: variational Bayesian neural network to prioritize important relationships of high-dimensional microbiome multiomics data. *Briefings in Bioinformatics*, 25(4), bbaf300.
- Link: https://academic.oup.com/bib/article/26/4/bbaf300/8185645

**Bayesian Compositional GLMs (2024)**
- Zhang, X., &amp; Yi, N. (2024). Bayesian compositional generalized linear models for analyzing microbiome data. *Statistics in Medicine*, 43(3), 477-496.
- Link: https://onlinelibrary.wiley.com/doi/10.1002/sim.9946
- Key contribution: Structured regularized horseshoe priors with phylogenetic structure

**BRACE (Bayesian Regression with Compositional Effects)**
- Koslovsky, M. D., et al. (2024). Bayesian compositional regression with flexible microbiome feature aggregation and selection. *arXiv preprint*.
- Link: https://arxiv.org/html/2406.01557
- Key contribution: Spiked Dirichlet process for functional grouping

**Bayesian Variable Shrinkage (2024)**
- Datta, J., &amp; Bandyopadhyay, D. (2024). Bayesian Variable Shrinkage and Selection in Compositional Data Regression: Application to Oral Microbiome. *Journal of the Indian Society for Probability and Statistics*, 25, 457-489.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC11470902/

**BORAL**
- Hui, F. K. (2016). boral ‚Äì Bayesian Ordination and Regression Analysis of Multivariate Abundance Data in R. *Methods in Ecology and Evolution*, 7(6), 744-750.
- Link: https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12514
- CRAN: https://cran.r-project.org/web/packages/boral/
- Key contribution: SSVS with ordination via JAGS

---

### Differential Abundance Method Benchmarks

**2024 Realistic Benchmark (Most Recent)**
- Thorsen, J., et al. (2024). A realistic benchmark for differential abundance testing and confounder adjustment in human microbiome studies. *Nature Communications*, 15, 8224.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC11423519/
- **Key finding**: &#34;Only classic methods (linear models, Wilcoxon, t-test), limma, and fastANCOM properly control false discoveries&#34;

**Comprehensive DA Methods Evaluation (2022)**
- Yang, L., &amp; Chen, J. (2022). A comprehensive evaluation of microbial differential abundance analysis methods: current status and potential solutions. *Microbiome*, 10, 130.
- Link: https://link.springer.com/article/10.1186/s40168-022-01320-0
- **Key findings**: ANCOM-BC and LinDA perform best; MaAsLin2 has FDR inflation issues

**38 Datasets Comparison (Nature Communications 2022)**
- Nearing, J. T., et al. (2022). Microbiome differential abundance methods produce different results across 38 datasets. *Nature Communications*, 13, 342.
- Link: https://www.nature.com/articles/s41467-022-28034-z
- **Key finding**: Different methods produce &#34;drastically different&#34; results

**Investigating DA Methods (PLOS Comp Bio 2022)**
- Calgaro, M., et al. (2022). Investigating differential abundance methods in microbiome data: A benchmark study. *PLOS Computational Biology*, 18(9), e1010467.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC9488820/
- **Key findings**: MaAsLin2 and Wilcoxon much less powerful; ALDEx2 virtually no power in some scenarios

**Parkinson&#39;s Disease Comparison**
- Jiang, D., et al. (2021). Comparison study of differential abundance testing methods using two large Parkinson disease gut microbiome datasets. *BMC Bioinformatics*, 22, 345.
- Link: https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-021-04193-6

**Benchmarking Correlated Data**
- Ma, Y., et al. (2023). Benchmarking differential abundance analysis methods for correlated microbiome sequencing data. *Briefings in Bioinformatics*, 24(1), bbac607.
- Link: https://academic.oup.com/bib/article/24/1/bbac607/6972878

---

### Adaptive FDR Methods

**IHW (Independent Hypothesis Weighting)**
- Ignatiadis, N., et al. (2016). Data-driven hypothesis weighting increases detection power in genome-scale multiple testing. *Nature Methods*, 13(7), 577-580.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC4930141/
- Bioconductor: https://bioconductor.org/packages/release/bioc/html/IHW.html
- **Key finding**: 25-68% power increase over Benjamini-Hochberg

**AdaFDR**
- Lei, L., &amp; Fithian, W. (2018). AdaPT: an interactive procedure for multiple testing with side information. *Journal of the Royal Statistical Society: Series B*, 80(4), 649-679.
- Link: https://www.nature.com/articles/s41467-019-11247-0
- **Key finding**: 32% more associations than BH on GTEx data

**Covariate Powered Cross-Weighted Multiple Testing**
- Ignatiadis, N., &amp; Huber, W. (2021). Covariate powered cross-weighted multiple testing. *Journal of the Royal Statistical Society Series B*, 83(4), 720-751.
- Link: https://academic.oup.com/jrsssb/article/83/4/720/7056032

**IHW for Epigenomics**
- Weinstein, A., et al. (2020). Leveraging biological and statistical covariates improves the detection power in epigenome-wide association testing. *Genome Biology*, 21, 88.
- Link: https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02001-7

---

### Two-Part Models for Longitudinal Data

**ZIBR (Zero-Inflated Beta Regression)**
- Chen, E. Z., &amp; Li, H. (2016). A two-part mixed-effects model for analyzing longitudinal microbiome compositional data. *Bioinformatics*, 32(17), 2611-2617.
- Link: https://academic.oup.com/bioinformatics/article/32/17/2611/2450750

**ZIGMM (Zero-Inflated Gaussian Mixed Models)**
- Zhang, X., et al. (2020). Zero-Inflated Gaussian mixed models for analyzing longitudinal microbiome data. *PLOS ONE*, 15(11), e0242073.
- Link: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0242073

**GLMMs for Microbiome (Book Chapter)**
- Zhang, X., &amp; Yi, N. (2023). Generalized Linear Mixed Models for Longitudinal Microbiome Data. In *Statistical Analysis of Microbiome Data*. Springer.
- Link: https://link.springer.com/chapter/10.1007/978-3-031-21391-5_17

**Linear Mixed-Effects Models (Book Chapter)**
- Zhang, X., &amp; Yi, N. (2023). Linear Mixed-Effects Models for Longitudinal Microbiome Data. In *Statistical Analysis of Microbiome Data*. Springer.
- Link: https://link.springer.com/chapter/10.1007/978-3-031-21391-5_15

---

### General Microbiome Analysis

**Data Pre-processing Review**
- Ghosh, T., et al. (2023). Data pre-processing for analyzing microbiome data ‚Äì A mini review. *Journal of Advanced Research*, 54, 39-48.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC10569954/

**Effects of Rare Taxa Filtering**
- Pasquier, J., et al. (2021). Effects of Rare Microbiome Taxa Filtering on Statistical Analysis. *Frontiers in Microbiology*, 11, 607325.
- Link: https://www.frontiersin.org/journals/microbiology/articles/10.3389/fmicb.2020.607325/full

**Best Practices for Microbiome Analysis in R**
- Gao, R., et al. (2023). The best practice for microbiome analysis using R. *Protein &amp; Cell*, 14(10), 713-725.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC10599642/

**Orchestrating Microbiome Analysis**
- Lahti, L., &amp; Shetty, S. (2024). Orchestrating Microbiome Analysis. Online book.
- Link: https://microbiome.github.io/OMA/
- Chapter on differential abundance: https://microbiome.github.io/OMA/docs/devel/pages/differential_abundance.html

**Statistical Challenges in Longitudinal Microbiome Data**
- Jiang, S., et al. (2022). Statistical challenges in longitudinal microbiome data analysis. *Briefings in Bioinformatics*, 23(4), bbac273.
- Link: https://academic.oup.com/bib/article/23/4/bbac273/6643459

**Machine Learning Best Practices**
- Marcos-Zambrano, L. J., et al. (2021). Machine learning approaches in microbiome research: challenges and best practices. *Frontiers in Microbiology*, 12, 636631.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC10556866/

---

### Virome-Specific

**Viromes vs Metagenomes (2024)**
- Beaulaurier, J., et al. (2024). Viromes vs. mixed community metagenomes: choice of method dictates interpretation of viral community ecology. *Microbiome*, 12, 190.
- Link: https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-024-01905-x
- **Key finding**: Total metagenomes biased toward abundant phages; viromes better for rare phages

**Targeted Viromes and Metagenomes**
- Leonard, S. P., et al. (2024). Targeted viromes and total metagenomes capture distinct components of bee gut phage communities. *Microbiome*, 12, 154.
- Link: https://link.springer.com/article/10.1186/s40168-024-01875-0

---

### Software Packages

**R Packages for Microbiome Analysis**

**microbiome**
- Lahti, L., &amp; Shetty, S. (2017). Tools for microbiome analysis in R. Bioconductor.
- Link: https://bioconductor.org/packages/release/bioc/html/microbiome.html
- GitHub: https://github.com/microbiome/microbiome
- Tutorials: https://microbiome.github.io/tutorials/

**phyloseq**
- McMurdie, P. J., &amp; Holmes, S. (2013). phyloseq: An R package for reproducible interactive analysis and graphics of microbiome census data. *PLOS ONE*, 8(4), e61217.
- Bioconductor: https://bioconductor.org/packages/release/bioc/html/phyloseq.html

**microbiomeMarker**
- Cao, Y., et al. (2022). microbiomeMarker: an R/Bioconductor package for microbiome marker identification and visualization. *Bioinformatics*, 38(16), 4027-4029.
- Link: https://academic.oup.com/bioinformatics/article/38/16/4027/6623408
- Bioconductor: https://bioconductor.org/packages/release/bioc/html/microbiomeMarker.html

**microViz**
- Barnett, D. J., et al. (2021). microViz: an R package for microbiome data visualization and statistics.
- Website: https://david-barnett.github.io/microViz/
- GitHub: https://github.com/david-barnett/microViz

**MicrobiomeExplorer**
- Hui, T., et al. (2021). MicrobiomeExplorer: an R package for the analysis and visualization of microbial communities. *Bioinformatics*, 37(20), 3687-3688.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC8193707/

**EasyMicroPlot (EMP)**
- Cheng, L., et al. (2021). EasyMicroPlot: An Efficient and Convenient R Package in Microbiome Downstream Analysis and Visualization for Clinical Study. *Frontiers in Genetics*, 12, 803627.
- Link: https://pmc.ncbi.nlm.nih.gov/articles/PMC8764268/

**MicrobiomeStat**
- Chen, J., &amp; Zhang, X. (2023). MicrobiomeStat: Statistical analysis tools for microbiome data.
- Website: https://www.microbiomestat.wiki/
- Filtering tutorial: https://www.microbiomestat.wiki/data-manipulation-and-transformation/data-filtering

**decontam**
- Davis, N. M., et al. (2018). Simple statistical identification and removal of contaminant sequences in marker-gene and metagenomics data. *Microbiome*, 6, 226.
- Bioconductor: https://bioconductor.org/packages/release/bioc/html/decontam.html

**ALDEx2**
- Fernandes, A. D., et al. (2013). ANOVA-like differential expression (ALDEx) analysis for mixed population RNA-Seq. *PLOS ONE*, 8(7), e67019.
- Bioconductor: https://bioconductor.org/packages/release/bioc/html/ALDEx2.html

**limma**
- Ritchie, M. E., et al. (2015). limma powers differential expression analyses for RNA-sequencing and microarray studies. *Nucleic Acids Research*, 43(7), e47.
- Bioconductor: https://bioconductor.org/packages/release/bioc/html/limma.html

---

### Additional Resources

**Core Microbiome Tutorial**
- Link: https://microbiome.github.io/tutorials/Core.html

**Subsetting Tutorial**
- Link: https://microbiome.github.io/OMA/docs/devel/pages/subsetting.html

**Data Filtering Tutorial**
- Link: https://microbiome.github.io/OMA/docs/devel/pages/quality_control.html

**Biostars Forum on Prevalence Thresholds**
- Link: https://www.biostars.org/p/9568251/

**QIIME2 Forum Discussions**
- DESeq2 vs ANCOM: https://forum.qiime2.org/t/deseq2-vs-ancom-results/17385

---

## Key Benchmark Summary

### Methods with Proper FDR Control (2024)
‚úÖ Wilcoxon rank-sum test
‚úÖ t-test
‚úÖ Linear models (classic)
‚úÖ limma
‚úÖ fastANCOM

### Methods with FDR Issues
‚ùå MaAsLin2 (dense signals, compositional effects)
‚ùå DESeq2 (severe FDR inflation)
‚ùå edgeR (severe FDR inflation)
‚ùå metagenomeSeq (FDR inflation)

### Best Overall Performance
üèÜ ANCOM-BC (with LinDA)
üèÜ LinDA (100-1000√ó faster than ANCOM-BC)
üèÜ ALDEx2 (most conservative, best at small n)

---

## Organized by Topic

### If you want to learn about...

**Filtering strategies**: PERFect, MI-based filtering, Effects of rare taxa filtering

**Method selection**: 2024 realistic benchmark, Comprehensive evaluation 2022, 38 datasets comparison

**Prevalence vs abundance**: MaAsLin3, Two-part models (ZIBR, ZIGMM)

**Complex designs**: ANCOM-BC2, LinDA, MaAsLin3, LDM

**Compositional methods**: ALDEx2, ANCOM-BC, LinDA

**Bayesian approaches**: Spike-and-slab models, BORAL, Bayesian compositional GLMs

**Adaptive FDR**: IHW, AdaFDR

**Longitudinal data**: Two-part models, LDM, Statistical challenges review

**Software tools**: microbiome, phyloseq, microbiomeMarker, microViz

**Best practices**: Data pre-processing review, Machine learning best practices, Orchestrating Microbiome Analysis

---

## Citation Guidelines

When citing methods in your paper:

**For filtering**:
- If using PERFect: Smirnova et al. 2019
- If using MI-based: Liu et al. 2022
- If using standard thresholds: Cite data pre-processing review (Ghosh et al. 2023)

**For differential abundance**:
- If using LinDA: Zhou et al. 2022
- If using ANCOM-BC2: Lin &amp; Peddada 2024
- If using MaAsLin3: Mallick et al. 2024
- If using ALDEx2: Fernandes et al. 2013
- If using limma: Ritchie et al. 2015

**For benchmarks** (to justify method choice):
- 2024: Thorsen et al. 2024 (most recent, realistic benchmark)
- 2022: Yang &amp; Chen 2022 (comprehensive evaluation)
- 2022: Nearing et al. 2022 (38 datasets comparison)

**For adaptive FDR**:
- If using IHW: Ignatiadis et al. 2016

---

## Online Resources

**Interactive tutorials**:
- Orchestrating Microbiome Analysis: https://microbiome.github.io/OMA/
- MicrobiomeStat wiki: https://www.microbiomestat.wiki/
- microbiome tutorials: https://microbiome.github.io/tutorials/

**GitHub repositories**:
- ANCOMBC: https://github.com/FrederickHuangLin/ANCOMBC
- MaAsLin3: https://github.com/biobakery/maaslin3
- MaAsLin2: https://github.com/biobakery/Maaslin2
- microbiome: https://github.com/microbiome/microbiome
- LDM: https://github.com/yijuanhu/LDM

**Package documentation**:
- Bioconductor packages: https://bioconductor.org/packages/release/BiocViews.html#___Microbiome
- CRAN task view (not specific to microbiome but useful): https://cran.r-project.org/web/views/

---

## Staying Current

**Key journals to follow**:
- *Microbiome*
- *Nature Methods*
- *Genome Biology*
- *Bioinformatics*
- *Briefings in Bioinformatics*
- *PLOS Computational Biology*

**Preprint servers**:
- bioRxiv (https://www.biorxiv.org/)
- medRxiv for clinical studies

**Conferences**:
- ISME (International Society for Microbial Ecology)
- ASM (American Society for Microbiology)
- Microbiome-focused workshops

---

## Last Updated

This reference list was compiled: 2025-01-12

**Note**: The field is rapidly evolving. Check for newer benchmarks and methods, especially:
- Updates to MaAsLin3 (just released Dec 2024)
- New benchmarks incorporating recent methods
- Extensions to LinDA and ANCOM-BC

---

## Quick Reference Cards

### When to cite what:

**Your filtering approach**:
- Data-driven: PERFect (Smirnova 2019) or MI-based (Liu 2022)
- Standard threshold: Data pre-processing review (Ghosh 2023)
- Justify why filtering: Effects of rare taxa filtering (Pasquier 2021)

**Your DA method**:
- Method paper (see table above)
- Benchmark supporting your choice (Thorsen 2024, Yang 2022, or Nearing 2022)

**Your sensitivity analysis**:
- Best practices review (Gao 2023 or Machine learning best practices)

**Your preprocessing**:
- Data pre-processing review (Ghosh 2023)
- Quality control: decontam paper if used

**If using prevalence testing**:
- MaAsLin3 (Mallick 2024) - cite the 77% prevalence finding
- Or two-part models (Chen &amp; Li 2016 for ZIBR)
</pre></div><button class="expand-btn">Show more</button></div>
</div></div></div>
<div class="message tool-reply" id="msg-2025-12-13T02-21-19-716Z"><div class="message-header"><span class="role-label">Tool reply</span><a href="#msg-2025-12-13T02-21-19-716Z" class="timestamp-link"><time datetime="2025-12-13T02:21:19.716Z" data-timestamp="2025-12-13T02:21:19.716Z">2025-12-13T02:21:19.716Z</time></a></div><div class="message-content"><div class="tool-result"><div class="truncatable"><div class="truncatable-content"><pre>File created successfully at: /Users/scotthandley/Code/smart_prev_filter/references.md</pre></div><button class="expand-btn">Show more</button></div></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-21-25-287Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-21-25-287Z" class="timestamp-link"><time datetime="2025-12-13T02:21:25.287Z" data-timestamp="2025-12-13T02:21:25.287Z">2025-12-13T02:21:25.287Z</time></a></div><div class="message-content">
<div class="thinking"><div class="thinking-label">Thinking</div><p>Perfect! Now let me list the files created so the user knows what was saved.</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-21-26-093Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-21-26-093Z" class="timestamp-link"><time datetime="2025-12-13T02:21:26.093Z" data-timestamp="2025-12-13T02:21:26.093Z">2025-12-13T02:21:26.093Z</time></a></div><div class="message-content">
<div class="tool-use bash-tool" data-tool-id="toolu_01665HUvESSrZaveU5NqH6Nd">
<div class="tool-header"><span class="tool-icon">$</span> Bash</div>
<div class="tool-description">List created markdown files with sizes</div><div class="truncatable"><div class="truncatable-content"><pre class="bash-command">ls -lh /Users/scotthandley/Code/smart_prev_filter/*.md</pre></div><button class="expand-btn">Show more</button></div>
</div></div></div>
<div class="message tool-reply" id="msg-2025-12-13T02-21-26-264Z"><div class="message-header"><span class="role-label">Tool reply</span><a href="#msg-2025-12-13T02-21-26-264Z" class="timestamp-link"><time datetime="2025-12-13T02:21:26.264Z" data-timestamp="2025-12-13T02:21:26.264Z">2025-12-13T02:21:26.264Z</time></a></div><div class="message-content"><div class="tool-result"><div class="truncatable"><div class="truncatable-content"><pre>-rw-------@ 1 scotthandley  staff    17K Dec 12 20:17 /Users/scotthandley/Code/smart_prev_filter/critical_analysis.md
-rw-------@ 1 scotthandley  staff    16K Dec 12 20:15 /Users/scotthandley/Code/smart_prev_filter/current_methods_review.md
-rw-------@ 1 scotthandley  staff    24K Dec 12 20:19 /Users/scotthandley/Code/smart_prev_filter/practical_recommendations.md
-rw-------@ 1 scotthandley  staff   8.1K Dec 12 20:13 /Users/scotthandley/Code/smart_prev_filter/README.md
-rw-------@ 1 scotthandley  staff    19K Dec 12 20:21 /Users/scotthandley/Code/smart_prev_filter/references.md</pre></div><button class="expand-btn">Show more</button></div></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-21-29-366Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-21-29-366Z" class="timestamp-link"><time datetime="2025-12-13T02:21:29.366Z" data-timestamp="2025-12-13T02:21:29.366Z">2025-12-13T02:21:29.366Z</time></a></div><div class="message-content">
<div class="thinking"><div class="thinking-label">Thinking</div><p>Great! Now let me create a quick summary for the user showing what was created.</p></div></div></div>
<div class="message assistant" id="msg-2025-12-13T02-21-45-012Z"><div class="message-header"><span class="role-label">Assistant</span><a href="#msg-2025-12-13T02-21-45-012Z" class="timestamp-link"><time datetime="2025-12-13T02:21:45.012Z" data-timestamp="2025-12-13T02:21:45.012Z">2025-12-13T02:21:45.012Z</time></a></div><div class="message-content">
<div class="assistant-text"><p>Perfect! I've saved our comprehensive discussion as 5 markdown documents in your <code>smart_prev_filter</code> directory:</p>
<h2>Created Files (84KB total)</h2>
<ol>
<li><strong>README.md</strong> (8.1 KB)</li>
<li>Executive summary and overview</li>
<li>Core problem statement</li>
<li>Key insights and findings</li>
<li>Verdict: "Need better tools, not complex theory"</li>
<li>Quick decision trees</li>
<li>
<p>Repository structure</p>
</li>
<li>
<p><strong>current_methods_review.md</strong> (16 KB)</p>
</li>
<li>Detailed review of all filtering and DA methods</li>
<li>PERFect, MI-based, ANCOM-BC2, MaAsLin3, LinDA, LDM</li>
<li>Bayesian approaches (spike-and-slab, BORAL, compositional models)</li>
<li>Two-part models for longitudinal data</li>
<li>Information-theoretic approaches</li>
<li>Benchmark results summary</li>
<li>
<p>Method comparison table by use case</p>
</li>
<li>
<p><strong>critical_analysis.md</strong> (17 KB)</p>
</li>
<li>Deep dive: "Is this really a serious problem?"</li>
<li>Phylogenetic analogy exploration</li>
<li>Evidence FOR and AGAINST severity</li>
<li>Why Bayesian optimization is probably overkill</li>
<li>Why diagnostics &gt; optimization</li>
<li>Alternative paradigms</li>
<li>Research gaps and opportunities</li>
<li>
<p><strong>Verdict: Moderate problem, transitioning from critical to legacy</strong></p>
</li>
<li>
<p><strong>practical_recommendations.md</strong> (24 KB)</p>
</li>
<li>Complete decision trees for method selection</li>
<li>Method-specific implementation guidance with code</li>
<li>Filtering strategies (data-driven, sensitivity analysis, hyperparameter tuning)</li>
<li>Practical workflows for different scenarios</li>
<li>Pre/post-filtering diagnostics checklist</li>
<li>Reporting standards and example methods statements</li>
<li>Common pitfalls to avoid</li>
<li>
<p>Quick reference comparison table</p>
</li>
<li>
<p><strong>references.md</strong> (19 KB)</p>
</li>
<li>Complete bibliography with links (100+ sources)</li>
<li>Organized by topic</li>
<li>Software packages with links</li>
<li>Citation guidelines</li>
<li>Key benchmark summary</li>
<li>Online resources and tutorials</li>
<li>How to stay current</li>
</ol>
<h2>Key Takeaways Captured</h2>
<p><strong>The Bottom Line:</strong>
- <strong>Real but transitioning problem</strong> - better methods reducing need for filtering
- <strong>Diagnostic tools &gt; Bayesian optimization</strong> - practical impact over theory
- <strong>Method choice matters more than filtering</strong> - MaAsLin isn't always the answer
- <strong>Build the diagnostic package</strong> - immediate practical value</p>
<p><strong>Most Surprising Finding:</strong>
2024 benchmarks show <strong>classic methods (Wilcoxon, limma) have better FDR control</strong> than MaAsLin2 for simple comparisons!</p>
<p>All files are ready for you to return to this project. The documents include implementation code, decision trees, and all the sources we discussed.</p></div></div></div>
        

<div class="pagination">
<a href="index.html" class="index-link">Index</a>
<a href="page-001.html">&larr; Prev</a>
<a href="page-001.html">1</a>
<span class="current">2</span>
<span class="disabled">Next &rarr;</span>
</div>

    </div>
    <script>
document.querySelectorAll('time[data-timestamp]').forEach(function(el) {
    const timestamp = el.getAttribute('data-timestamp');
    const date = new Date(timestamp);
    const now = new Date();
    const isToday = date.toDateString() === now.toDateString();
    const timeStr = date.toLocaleTimeString(undefined, { hour: '2-digit', minute: '2-digit' });
    if (isToday) { el.textContent = timeStr; }
    else { el.textContent = date.toLocaleDateString(undefined, { month: 'short', day: 'numeric' }) + ' ' + timeStr; }
});
document.querySelectorAll('pre.json').forEach(function(el) {
    let text = el.textContent;
    text = text.replace(/"([^"]+)":/g, '<span style="color: #ce93d8">"$1"</span>:');
    text = text.replace(/: "([^"]*)"/g, ': <span style="color: #81d4fa">"$1"</span>');
    text = text.replace(/: (\d+)/g, ': <span style="color: #ffcc80">$1</span>');
    text = text.replace(/: (true|false|null)/g, ': <span style="color: #f48fb1">$1</span>');
    el.innerHTML = text;
});
document.querySelectorAll('.truncatable').forEach(function(wrapper) {
    const content = wrapper.querySelector('.truncatable-content');
    const btn = wrapper.querySelector('.expand-btn');
    if (content.scrollHeight > 250) {
        wrapper.classList.add('truncated');
        btn.addEventListener('click', function() {
            if (wrapper.classList.contains('truncated')) { wrapper.classList.remove('truncated'); wrapper.classList.add('expanded'); btn.textContent = 'Show less'; }
            else { wrapper.classList.remove('expanded'); wrapper.classList.add('truncated'); btn.textContent = 'Show more'; }
        });
    }
});
</script>
</body>
</html>